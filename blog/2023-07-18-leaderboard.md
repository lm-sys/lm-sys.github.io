---
title: "Chatbot Arena Leaderboard Week 12: Conversation Dataset Release"
author: "LMSYS Org"
date: "July 18, 2023"
previewImg: /images/blog/arena/cover.png
---

Since its launch three months ago, [Chatbot Arena](https://lmsys.org/blog/2023-05-03-arena/) has become a widely cited LLM evaluation platform that emphasizes large-scale, community-based, and interactive human evaluation. In that short time span, we collected around 53K votes from 19K unique IP addresses for 22 models.

In this blog post, we are releasing an updated leaderboard with more models and two datasets for human preferences related study:
- **33K crowd-sourced conversations** with human preference annotations from Chatbot Arena. ([link](https://huggingface.co/datasets/lmsys/chatbot_arena_conversations))
- **3K expert-level human annotations** from MT-bench. ([link](https://huggingface.co/datasets/lmsys/mt_bench_human_judgments))

## Updated Leaderboard

We are hosting the latest leaderboard at [lmsys/chatbot-arena-leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard). Below is a screenshot. Since the last update, we added two 30B models: Vicuna-33B-v1.3 and MPT-30B-chat, both of which perform very well in the arena.
We also tested the MT-bench scores (with GPT-4 evaluation) for new models including Claude-2, WizardLM-13B-v1.1, XGen-7B-8K-Inst, and ChatGLM2-6B. You are welcome to check out the interactive [lmsys/chatbot-arena-leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) to sort the models according to different metrics.

<img src="/images/blog/leaderboard_week12/leaderboard.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto;"></img>
<p style="color:gray; text-align: center;">Figure 1. Chatbot Arena Leaderboard. </p>

## Dataset 1: 33K Chatbot Arena Conversation Data
Link: [lmsys/chatbot_arena_conversations](https://huggingface.co/datasets/lmsys/chatbot_arena_conversations)

This dataset contains 33K cleaned conversations collected on Chatbot Arena from April to June 2023. Each sample includes two model names, their full conversation text, the user vote and anonymized user ID, a detected language tag, an OpenAI moderation API tag, an additional toxic tag, and a timestamp.

To ensure the safe release of data, we have attempted to remove all conversations that contain personally identifiable information (PII). In addition, we have included the OpenAI moderation API output to flag inappropriate conversations. However, we have chosen not to remove all of these conversations so that researchers can study safety-related questions associated with LLM usage in the wild as well as the OpenAI moderation process. As an example, we included additional toxic tags that are generated by our own toxic tagger, which are trained by fine-tuning T5 and RoBERTa on manually labeled data.

### Uniqueness and Potential Usage
Compared to existing human preference datasets like [Anthropic/hh-rlhf](https://huggingface.co/datasets/Anthropic/hh-rlhf), and [OpenAssistant/oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1). This dataset
- Contains the outputs of 20 LLMs including stronger LLMs such as GPT-4 and Claude-v1. It also contains many failure cases of these state-of-the-art models.
- Contains unrestricted conversations from over 13K users in the wild.

Therefore, we believe this data will help the AI research community answer important questions around topics like:
- Characteristics of real-world user prompts
- Train better models with RLHF
- Improve and evaluate LLM evaluation methods
- Build model selection and request dispatching algorithms
- Study the design and application of inappropriate content filtering mechanisms

### Disclaimer
- This dataset includes offensive conversations. It is not intended for training dialogue agents without applying appropriate filtering measures.
- Statements or opinions made in this dataset do not reflect the views of researchers or institutions involved in the data collection effort.
- Users of this data are responsible for ensuring its appropriate use, which includes abiding by any applicable laws and regulations.
- Please contact us if you find any issues with the dataset.

### Visualization and Elo Rating Calculation
This Colab [notebook](https://colab.research.google.com/drive/1J2Wf7sxc9SVmGnSX_lImhT246pxNVZip?usp=sharing) provides some visualizations and shows how to compute Elo ratings with the dataset.

## Dataset 2: 3K MT-bench Human Annotations
Link: [lmsys/mt_bench_human_judgments](https://huggingface.co/datasets/lmsys/mt_bench_human_judgments)

In addition to the crowd-sourced evaluation with Chatbot Arena, we also conducted a controlled human evaluation with MT-bench.

This dataset contains 3.3K expert-level human annotations for model responses generated by 6 models in response to 80 MT-bench questions. The 6 models are GPT-4, GPT-3.5, Claud-v1, Vicuna-13B, Alpaca-13B, and LLaMA-13B. The annotators are mostly graduate students with expertise in the topic areas of each of the questions. The details of data collection can be found in our [paper](https://arxiv.org/abs/2306.05685).

### Agreement Calculation
This Colab [notebook](https://colab.research.google.com/drive/1ctgygDRJhVGUJTQy8-bRZCl1WNcT8De6?usp=sharing) shows how to compute the agreement between humans and GPT-4 judge with the dataset. Our results show that humans and GPT-4 judge achieve over 80\% agreement, the same level of agreement between humans.

## Acknowlement
We thank the whole community for contributing to the arena dataset.
