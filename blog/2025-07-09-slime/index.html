<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/styles/atom-one-light.min.css"/><title>slime: An SGLang-Native Post-Training Framework for RL Scaling | LMSYS Org</title><meta name="title" content="slime: An SGLang-Native Post-Training Framework for RL Scaling | LMSYS Org"/><meta property="og:title" content="slime: An SGLang-Native Post-Training Framework for RL Scaling | LMSYS Org"/><meta name="twitter:title" content="slime: An SGLang-Native Post-Training Framework for RL Scaling | LMSYS Org"/><meta name="description" content="&lt;h2&gt;&lt;a id=&quot;vision-that-drives-slime&quot; class=&quot;anchor&quot; href=&quot;#vision-that-drives-slime&quot; aria-hidden=&quot;true&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; class=&quot;octicon octicon-link&quot; ..."/><meta property="og:description" content="&lt;h2&gt;&lt;a id=&quot;vision-that-drives-slime&quot; class=&quot;anchor&quot; href=&quot;#vision-that-drives-slime&quot; aria-hidden=&quot;true&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; class=&quot;octicon octicon-link&quot; ..."/><meta name="twitter:description" content="&lt;h2&gt;&lt;a id=&quot;vision-that-drives-slime&quot; class=&quot;anchor&quot; href=&quot;#vision-that-drives-slime&quot; aria-hidden=&quot;true&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; class=&quot;octicon octicon-link&quot; ..."/><meta property="og:image" content="https://lmsys.org/images/blog/slime/slime.png"/><meta name="twitter:image" content="https://lmsys.org/images/blog/slime/slime.png"/><meta name="twitter:image:alt" content="The text: LLMSYS Org, Large Model Systems Organization."/><meta property="og:type" content="website"/><meta property="og:url" content="https://lmsys.org/blog/2025-07-09-slime"/><meta name="twitter:url" content="https://lmsys.org/blog/2025-07-09-slime"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1d1d1f"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.jpeg"/><link rel="icon" href="/favicon.jpeg" type="image/jpg"/><meta name="next-head-count" content="20"/><script src="/mathjax.js" defer=""></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js" defer=""></script><link rel="preload" href="/_next/static/css/664049df48ded145.css" as="style"/><link rel="stylesheet" href="/_next/static/css/664049df48ded145.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eef2afd147d8eda9.js" defer=""></script><script src="/_next/static/chunks/286-48ebbaba72d91976.js" defer=""></script><script src="/_next/static/chunks/807-a4eae1dfa8bfbe9f.js" defer=""></script><script src="/_next/static/chunks/138-efd6d72a198878c6.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-c9fe776063d24120.js" defer=""></script><script src="/_next/static/433Rw7afKHCar-Gdg6TNW/_buildManifest.js" defer=""></script><script src="/_next/static/433Rw7afKHCar-Gdg6TNW/_ssgManifest.js" defer=""></script><script src="/_next/static/433Rw7afKHCar-Gdg6TNW/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-sky md:text-paper md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LMSYS ORG</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/blog/">Blog</a><a href="/about/">About</a><a href="/donations/">Donations</a><a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">Chatbot Arena (graduated)</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://slack.sglang.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1d1d1f;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/blog/">Blog</a></p><p><a href="/about/">About</a></p><p><a href="/donations/">Donations</a></p><p><a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">Chatbot Arena (graduated)</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.gg/HSWAKCrnFx" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-sky grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5" lang="en"><h1 lang="en" style="hyphens:auto" class="text-4xl md:text-4xl w-full font-bold break-words">slime: An SGLang-Native Post-Training Framework for RL Scaling</h1><p class="text-xl pt-2 pb-2">by: <!-- -->The slime Team<!-- -->,<!-- --> <!-- -->Jul 09, 2025<!-- --></p><hr/><div class="pt-2 article"><h2><a id="vision-that-drives-slime" class="anchor" href="#vision-that-drives-slime" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Vision That Drives slime</h2>
<p>We believe in RL. We believe RL is the final piece toward AGI.</p>
<p>If you feel the same way, you'll share our vision:</p>
<ul>
<li>Every field should be end-to-end RLed and every task should become an agent environment.</li>
<li>Every RL run should last longer, and every model should scale larger.</li>
<li>RL systems should integrate seamlessly with existing infrastructure, letting us focus on new ideas instead of boilerplate engineering.</li>
</ul>
<p>That's why we present <a href="https://github.com/THUDM/slime">slime</a>, a post-training framework designed to be:</p>
<ul>
<li><strong>Versatile</strong> – with a fully customizable rollout interface and flexible training setups (colocated or decoupled, synchronous or asynchronous, RL or SFT cold start).</li>
<li><strong>Performant</strong> - integrating SGLang for inference and Megatron-LM for training, natively.</li>
<li><strong>Maintainable</strong> - with a lightweight codebase and smooth transition from Megatron pretraining to SGLang deployment.</li>
</ul>
<p>In short, a post-training framework for RL scaling.</p>
<p>Here’s how we made it happen.</p>
<h2><a id="customizability-brings-freedom" class="anchor" href="#customizability-brings-freedom" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Customizability Brings Freedom</h2>
<blockquote>
<p>We should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries.</p>
<p>— <em>The Bitter Lesson</em></p>
</blockquote>
<p>A prevailing misconception within the RL community is the need for separate frameworks for different tasks: one for plain math, one for multi-turn tool calling, one for asynchronous training, one for agentic tasks, and so on. Forking and maintaining multiple frameworks is dreadful, leading to time-wasting bugfix cherry-picking, or worse, training crashes by missing patches.</p>
<p>It wasn’t always like this: no one forks PyTorch just for a new dataloader. We believe the current chaos stems from the trap of dictating how people should build their applications. If we insist on defining a universal template for every rollout scenario, we’ll inevitably create an RL framework that meets only a fraction of real-world needs.</p>
<p>slime views the data sampling in RL differently. We manage all SGLang servers within slime with <a href="https://github.com/sgl-project/sglang/tree/main/sgl-router">sgl-router</a> and provide an interface for the data generation component, <strong>allowing users to inject custom logic and freely interact with SGLang servers</strong>. Unleash their creativity.</p>
<p><img src="/images/blog/slime/slime-arch.png" alt="slime architecture"></p>
<p>With the sgl-router, users only need to send HTTP requests to a single endpoint. By exposing this endpoint, complex agent environments can directly interact with slime through an OpenAI-compatible API — no need to modify the environment, and training-deployment consistency is preserved.</p>
<p>Regarding training schemes, slime uses Ray for resource management, enabling <strong>colocated</strong> (same GPUs) or <strong>decoupled</strong> (separate GPUs) setups with a single flag (<code>--colocate</code>).</p>
<p>And with Ray's asynchronous execution via <code>.remote()</code>, slime naturally supports asynchronous training. Changing synchronization behavior is as simple as moving the <code>ray.get</code> operation. And to make experimenting with different strategies easy, we didn't wrap the code with trainer classes, but simply exposed the training loop in entrypoint  <code>train.py</code>.</p>
<h2><a id="built-for-performance" class="anchor" href="#built-for-performance" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Built for Performance</h2>
<p><strong>A decent RL framework must be fast and consistently fast.</strong></p>
<p><strong>Fast</strong> means leveraging the fastest inference and training frameworks.</p>
<p>Unlike pre-training, RL workloads involve tons of online sampling during training, which makes the inference performance crucial. Therefore, slime exclusively integrates SGLang, and deliberately delivers an SGLang-native experience.</p>
<p>So what does ‘SGLang-native’ mean? It means you can take full advantage of all SGLang optimizations — using SGLang inside slime feels just like using it standalone. To make that possible:</p>
<ul>
<li>slime internally launches SGLang servers in a <strong>server-based mode</strong>.</li>
<li>slime implements <strong>seamless pass-through</strong> for all SGLang parameters (with a <code>--sglang</code> prefix), ensuring that all optimization options can be enabled. For instance, you can pass <code>--sglang-enable-ep-moe</code>, <code>--sglang-enable-dp-attention</code> and <code>--sglang-enable-deepep-moe</code> for the powerful multi-node MoE inference capabilities.</li>
<li>slime provides an <strong>SGLang-only debug mode</strong> (<code>--debug-rollout-only</code>) for easy performance tuning.</li>
</ul>
<p>Together, we can reproduce the standalone performance of SGLang within slime. Even the base image of slime is built on <code>lmsysorg/sglang:dev</code>.</p>
<p>For training, slime integrates the battle-tested Megatron-LM, aiming for a similarly native pre-training experience:</p>
<ul>
<li>slime also implements <strong>seamless pass-through</strong> for all Megatron parameters.</li>
<li>slime supports <strong>all Megatron parallelisms</strong> (TP, PP, EP, CP) and monitors training MFU.</li>
<li>slime offers a <strong>Megatron-only debug mode</strong> (<code>--debug-train-only</code>) and supports storing sampling data for reproducibility.</li>
</ul>
<p>Megatron can be notoriously complex, so we also provide checkpoint conversion tools to simplify its use.</p>
<p><strong>Consistently fast</strong> means keeping pace with the evolving inference and training frameworks.</p>
<p>If you ever followed the <a href="https://github.com/sgl-project/sglang/pulls">SGLang PR list</a>, you will be astonished by its rapid evolution. Megatron, on the other hand, is often heavily customized, with every organization maintaining its own fork. slime is designed to keep pace with upstream changes in SGLang and adapt to optimizations in in-house Megatron variants. This is another reason why we pursue native support for SGLang and Megatron. The parameter pass-through makes upgrading effortless.</p>
<p>Beyond optimizing inference and training frameworks, we also tackled RL-specific workloads. When SGLang needs changes to support these workflows, we work closely with the SGLang team to upstream patches—so slime can stay native, even as RL logic evolves. Examples include:</p>
<p><strong>Optimizing weight updates</strong>: Unlike inference tasks, RL training involves frequent updates to model weights. To address this, we’ve introduced several optimizations in SGLang:</p>
<ul>
<li>Parameter updates for MoE models under various parallelism strategies (<a href="https://github.com/sgl-project/sglang/pull/6265">#6265</a>, <a href="https://github.com/sgl-project/sglang/pull/6308">#6308</a>, <a href="https://github.com/sgl-project/sglang/pull/6311">#6311</a>).</li>
<li>Bucketed parameter update support to reduce overhead (<a href="https://github.com/sgl-project/sglang/pull/7292">#7292</a>).</li>
</ul>
<p><strong><code>/abort_request</code> for dynamic sampling</strong>: In RL algorithms that require oversampling, such as <a href="https://arxiv.org/abs/2503.14476">DAPO</a>, some requests may continue running even after sufficient data has been collected. In collaboration with the <a href="https://github.com/inclusionAI/AReaL">AReal</a> team, we designed an new endpoint: <code>/abort_request</code>. This endpoint enables:</p>
<ul>
<li>Immediate termination of on-going requests.</li>
<li>Reclaiming partially generated content, which enables partial rollouts.</li>
</ul>
<p>Implemented in <a href="https://github.com/sgl-project/sglang/pull/6698">#6698</a>, <a href="https://github.com/sgl-project/sglang/pull/6855">#6855</a>, <a href="https://github.com/sgl-project/sglang/pull/6184">#6184</a>, <a href="https://github.com/sgl-project/sglang/pull/5966">#5966</a>.</p>
<h2><a id="lightweight-and-extensible" class="anchor" href="#lightweight-and-extensible" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Lightweight and Extensible</h2>
<p>Focusing on customization and performance, slime:</p>
<ol>
<li>Provides a customizable rollout interface.</li>
<li>Uses Ray for GPU management and asynchronous execution.</li>
<li>Integrates SGLang for inference and Megatron for training.</li>
<li>Provides weight updates between training and inference.</li>
</ol>
<p>Pretty straightforward, right? slime transfers complexity from the framework to user-defined pipelines and core libraries (SGLang and Megatron), resulting in a lightweight, easily maintainable codebase.</p>
<p>But it doesn’t stop at RL.</p>
<p>Thanks to its modular design and powerful backends, slime can naturally extend to other post-training workflows with minimal extra code:</p>
<ul>
<li><strong>SFT</strong>: Load Megatron and use token prediction loss.</li>
<li><strong>Rejection Sampling</strong>: Use SGLang for filter, followed by Megatron SFT.</li>
</ul>
<p><em>(Note that SFT feature is now in experimental state.)</em></p>
<p>Beyond that, slime's native integration <strong>seamlessly bridges pre-training to online services</strong>. We can use Megatron for pre-training, switch to slime (which integrates both Megatron and SGLang) for post-training, and finally use SGLang directly for evaluation and deployment. This eliminates the cumbersome and error-prone steps of converting checkpoint formats and aligning precision between frameworks.</p>
<p>The unified pipeline saves us from tedious glue code, freeing us to focus on what really matters: better RL. Hurray!</p>
<h2><a id="roadmap" class="anchor" href="#roadmap" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Roadmap</h2>
<p>The journey of RL scaling has just begun, and slime is continuously evolving. In the next phase, we will focus on:</p>
<ol>
<li>Collaborating with the SGLang team to explore optimal RL training strategies for large-scale MoE models.</li>
<li>Supporting broader post-training workflows, strengthening the pre-training-to-production bridge.</li>
<li>Adding native PyTorch training backend support to lower the entry barrier.</li>
</ol>
<p>We hope slime accelerates your RL scaling journey and turns your innovative ideas into reality. Contributions and conversations are always welcome!</p>
<p>Special thanks to the AMD GenAI - Foundation Model Team for Day-1 AMD hardware support.</p>
</div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"slime: An SGLang-Native Post-Training Framework for RL Scaling","author":"The slime Team","date":"July 9, 2025","previewImg":"/images/blog/slime/slime.png"},"content":"\n## Vision That Drives slime\n\nWe believe in RL. We believe RL is the final piece toward AGI.\n\nIf you feel the same way, you'll share our vision:\n\n- Every field should be end-to-end RLed and every task should become an agent environment.\n- Every RL run should last longer, and every model should scale larger.\n- RL systems should integrate seamlessly with existing infrastructure, letting us focus on new ideas instead of boilerplate engineering.\n\nThat's why we present [slime](https://github.com/THUDM/slime), a post-training framework designed to be:\n\n- **Versatile** – with a fully customizable rollout interface and flexible training setups (colocated or decoupled, synchronous or asynchronous, RL or SFT cold start).\n- **Performant** - integrating SGLang for inference and Megatron-LM for training, natively.\n- **Maintainable** - with a lightweight codebase and smooth transition from Megatron pretraining to SGLang deployment.\n\nIn short, a post-training framework for RL scaling.\n\nHere’s how we made it happen.\n\n## Customizability Brings Freedom\n\n\u003e We should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries.\n\u003e \n\u003e \n\u003e — *The Bitter Lesson*\n\u003e \n\nA prevailing misconception within the RL community is the need for separate frameworks for different tasks: one for plain math, one for multi-turn tool calling, one for asynchronous training, one for agentic tasks, and so on. Forking and maintaining multiple frameworks is dreadful, leading to time-wasting bugfix cherry-picking, or worse, training crashes by missing patches.\n\nIt wasn’t always like this: no one forks PyTorch just for a new dataloader. We believe the current chaos stems from the trap of dictating how people should build their applications. If we insist on defining a universal template for every rollout scenario, we’ll inevitably create an RL framework that meets only a fraction of real-world needs.\n\nslime views the data sampling in RL differently. We manage all SGLang servers within slime with [sgl-router](https://github.com/sgl-project/sglang/tree/main/sgl-router) and provide an interface for the data generation component, **allowing users to inject custom logic and freely interact with SGLang servers**. Unleash their creativity.\n\n![slime architecture](/images/blog/slime/slime-arch.png)\n\nWith the sgl-router, users only need to send HTTP requests to a single endpoint. By exposing this endpoint, complex agent environments can directly interact with slime through an OpenAI-compatible API — no need to modify the environment, and training-deployment consistency is preserved.\n\nRegarding training schemes, slime uses Ray for resource management, enabling **colocated** (same GPUs) or **decoupled** (separate GPUs) setups with a single flag (`--colocate`).\n\nAnd with Ray's asynchronous execution via `.remote()`, slime naturally supports asynchronous training. Changing synchronization behavior is as simple as moving the `ray.get` operation. And to make experimenting with different strategies easy, we didn't wrap the code with trainer classes, but simply exposed the training loop in entrypoint  `train.py`.\n\n## Built for Performance\n\n**A decent RL framework must be fast and consistently fast.**\n\n**Fast** means leveraging the fastest inference and training frameworks.\n\nUnlike pre-training, RL workloads involve tons of online sampling during training, which makes the inference performance crucial. Therefore, slime exclusively integrates SGLang, and deliberately delivers an SGLang-native experience.\n\nSo what does ‘SGLang-native’ mean? It means you can take full advantage of all SGLang optimizations — using SGLang inside slime feels just like using it standalone. To make that possible:\n\n- slime internally launches SGLang servers in a **server-based mode**.\n- slime implements **seamless pass-through** for all SGLang parameters (with a `--sglang` prefix), ensuring that all optimization options can be enabled. For instance, you can pass `--sglang-enable-ep-moe`, `--sglang-enable-dp-attention` and `--sglang-enable-deepep-moe` for the powerful multi-node MoE inference capabilities.\n- slime provides an **SGLang-only debug mode** (`--debug-rollout-only`) for easy performance tuning.\n\nTogether, we can reproduce the standalone performance of SGLang within slime. Even the base image of slime is built on `lmsysorg/sglang:dev`.\n\nFor training, slime integrates the battle-tested Megatron-LM, aiming for a similarly native pre-training experience:\n\n- slime also implements **seamless pass-through** for all Megatron parameters.\n- slime supports **all Megatron parallelisms** (TP, PP, EP, CP) and monitors training MFU.\n- slime offers a **Megatron-only debug mode** (`--debug-train-only`) and supports storing sampling data for reproducibility.\n\nMegatron can be notoriously complex, so we also provide checkpoint conversion tools to simplify its use.\n\n**Consistently fast** means keeping pace with the evolving inference and training frameworks.\n\nIf you ever followed the [SGLang PR list](https://github.com/sgl-project/sglang/pulls), you will be astonished by its rapid evolution. Megatron, on the other hand, is often heavily customized, with every organization maintaining its own fork. slime is designed to keep pace with upstream changes in SGLang and adapt to optimizations in in-house Megatron variants. This is another reason why we pursue native support for SGLang and Megatron. The parameter pass-through makes upgrading effortless.\n\nBeyond optimizing inference and training frameworks, we also tackled RL-specific workloads. When SGLang needs changes to support these workflows, we work closely with the SGLang team to upstream patches—so slime can stay native, even as RL logic evolves. Examples include:\n\n**Optimizing weight updates**: Unlike inference tasks, RL training involves frequent updates to model weights. To address this, we’ve introduced several optimizations in SGLang:\n    \n  - Parameter updates for MoE models under various parallelism strategies ([#6265](https://github.com/sgl-project/sglang/pull/6265), [#6308](https://github.com/sgl-project/sglang/pull/6308), [#6311](https://github.com/sgl-project/sglang/pull/6311)).\n  - Bucketed parameter update support to reduce overhead ([#7292](https://github.com/sgl-project/sglang/pull/7292)).\n\n**`/abort_request` for dynamic sampling**: In RL algorithms that require oversampling, such as [DAPO](https://arxiv.org/abs/2503.14476), some requests may continue running even after sufficient data has been collected. In collaboration with the [AReal](https://github.com/inclusionAI/AReaL) team, we designed an new endpoint: `/abort_request`. This endpoint enables:\n    \n  - Immediate termination of on-going requests.\n  - Reclaiming partially generated content, which enables partial rollouts.\n    \nImplemented in [#6698](https://github.com/sgl-project/sglang/pull/6698), [#6855](https://github.com/sgl-project/sglang/pull/6855), [#6184](https://github.com/sgl-project/sglang/pull/6184), [#5966](https://github.com/sgl-project/sglang/pull/5966).\n    \n\n## Lightweight and Extensible\n\nFocusing on customization and performance, slime:\n\n1. Provides a customizable rollout interface.\n2. Uses Ray for GPU management and asynchronous execution.\n3. Integrates SGLang for inference and Megatron for training.\n4. Provides weight updates between training and inference.\n\nPretty straightforward, right? slime transfers complexity from the framework to user-defined pipelines and core libraries (SGLang and Megatron), resulting in a lightweight, easily maintainable codebase.\n\nBut it doesn’t stop at RL.\n\nThanks to its modular design and powerful backends, slime can naturally extend to other post-training workflows with minimal extra code:\n\n- **SFT**: Load Megatron and use token prediction loss.\n- **Rejection Sampling**: Use SGLang for filter, followed by Megatron SFT.\n\n*(Note that SFT feature is now in experimental state.)*\n\nBeyond that, slime's native integration **seamlessly bridges pre-training to online services**. We can use Megatron for pre-training, switch to slime (which integrates both Megatron and SGLang) for post-training, and finally use SGLang directly for evaluation and deployment. This eliminates the cumbersome and error-prone steps of converting checkpoint formats and aligning precision between frameworks.\n\nThe unified pipeline saves us from tedious glue code, freeing us to focus on what really matters: better RL. Hurray!\n\n## Roadmap\n\nThe journey of RL scaling has just begun, and slime is continuously evolving. In the next phase, we will focus on:\n\n1. Collaborating with the SGLang team to explore optimal RL training strategies for large-scale MoE models.\n2. Supporting broader post-training workflows, strengthening the pre-training-to-production bridge.\n3. Adding native PyTorch training backend support to lower the entry barrier.\n\nWe hope slime accelerates your RL scaling journey and turns your innovative ideas into reality. Contributions and conversations are always welcome!\n\nSpecial thanks to the AMD GenAI - Foundation Model Team for Day-1 AMD hardware support.\n","slug":"2025-07-09-slime"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"2025-07-09-slime"},"buildId":"433Rw7afKHCar-Gdg6TNW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>