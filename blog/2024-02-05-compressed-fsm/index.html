<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Fast JSON Decoding for Local LLMs with Compressed Finite State Machine | LMSYS Org</title><meta name="title" content="Fast JSON Decoding for Local LLMs with Compressed Finite State Machine | LMSYS Org"/><meta property="og:title" content="Fast JSON Decoding for Local LLMs with Compressed Finite State Machine | LMSYS Org"/><meta name="twitter:title" content="Fast JSON Decoding for Local LLMs with Compressed Finite State Machine | LMSYS Org"/><meta name="description" content="&lt;p&gt;Constraining an LLM to consistently generate valid JSON or YAML that adheres to a specific schema is a critical feature for many applications.
In this blo..."/><meta property="og:description" content="&lt;p&gt;Constraining an LLM to consistently generate valid JSON or YAML that adheres to a specific schema is a critical feature for many applications.
In this blo..."/><meta name="twitter:description" content="&lt;p&gt;Constraining an LLM to consistently generate valid JSON or YAML that adheres to a specific schema is a critical feature for many applications.
In this blo..."/><meta property="og:image" content="https://lmsys.org/images/blog/compressed_fsm/demo.gif"/><meta name="twitter:image" content="https://lmsys.org/images/blog/compressed_fsm/demo.gif"/><meta name="twitter:image:alt" content="The text: LLMSYS Org, Large Model Systems Organization."/><meta property="og:type" content="website"/><meta property="og:url" content="https://lmsys.org/blog/2024-02-05-compressed-fsm"/><meta name="twitter:url" content="https://lmsys.org/blog/2024-02-05-compressed-fsm"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1d1d1f"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.jpeg"/><link rel="icon" href="/favicon.jpeg" type="image/jpg"/><meta name="next-head-count" content="19"/><script src="/mathjax.js" defer=""></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js" defer=""></script><link rel="preload" href="/_next/static/css/9aa18d40847551db.css" as="style"/><link rel="stylesheet" href="/_next/static/css/9aa18d40847551db.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-a0cb9ddcff62d761.js" defer=""></script><script src="/_next/static/chunks/286-48ebbaba72d91976.js" defer=""></script><script src="/_next/static/chunks/807-a4eae1dfa8bfbe9f.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-3d139df5a55b1694.js" defer=""></script><script src="/_next/static/QR8Ie-cIm8I8VX1A2KzTJ/_buildManifest.js" defer=""></script><script src="/_next/static/QR8Ie-cIm8I8VX1A2KzTJ/_ssgManifest.js" defer=""></script><script src="/_next/static/QR8Ie-cIm8I8VX1A2KzTJ/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-sky md:text-paper md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LMSYS ORG</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/blog/">Blog</a><a href="/about/">About</a><a href="/donations/">Donations</a><a href="https://arena.lmsys.org" target="_blank" rel="noopener noreferrer">Chatbot Arena</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.gg/HSWAKCrnFx" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1d1d1f;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/blog/">Blog</a></p><p><a href="/about/">About</a></p><p><a href="/donations/">Donations</a></p><p><a href="https://arena.lmsys.org" target="_blank" rel="noopener noreferrer">Chatbot Arena</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.gg/HSWAKCrnFx" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-sky grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5" lang="en"><h1 lang="en" style="hyphens:auto" class="text-4xl md:text-4xl w-full font-bold break-words">Fast JSON Decoding for Local LLMs with Compressed Finite State Machine</h1><p class="text-xl pt-2 pb-2">by: <!-- -->Liangsheng Yin, Ying Sheng, Lianmin Zheng<!-- -->,<!-- --> <!-- -->Feb 05, 2024<!-- --></p><hr/><div class="pt-2 article"><p>Constraining an LLM to consistently generate valid JSON or YAML that adheres to a specific schema is a critical feature for many applications.
In this blog post, we introduce an optimization that significantly accelerates this type of constrained decoding. Our approach utilizes a compressed finite state machine and is compatible with any regular expression, thereby accommodating any JSON or YAML schema.
Distinct from existing systems that decode one token at one step, our method analyzes the finite state machine of a regular expression, compresses singular transition paths, and decodes <u>multiple tokens in a single step</u> whenever feasible. In comparison to state-of-the-art systems (guidance + llama.cpp, outlines + vLLM), our method can reduce the latency by up to 2x and boost throughput by up to 2.5x.
This optimization also makes constrained decoding even faster than normal deocding.
You can try it now on <a href="https://github.com/sgl-project/sglang/tree/main?tab=readme-ov-file#json-decoding">SGLang</a>.</p>
<p><img src="/images/blog/compressed_fsm/demo.gif" style="width: 100%; max-width: 100%; margin-left: auto; margin-right: auto; margin-bottom: auto"></img></p>
<p style="color:gray; text-align: center;">
Figure 1: Comparison of SGLang and Outlines + vLLM in JSON Decoding
</p>
<h2><a id="background" class="anchor" href="#background" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Background</h2>
<p><a href="https://en.wikipedia.org/wiki/JSON">JSON</a> is one of the most important formats for data interchange. Requiring LLMs to always generate valid JSON can render the output of the LLM easily parsable in a structured manner. Recognizing its significance, OpenAI introduced the <a href="https://platform.openai.com/docs/guides/text-generation/json-mode">JSON mode</a>, which constrains the model to always return a valid JSON object. However, more  fine-grained control is often needed to ensure that the generated JSON object adheres to a specific <a href="https://json-schema.org/">schema</a>, such as</p>
<p><img src="/images/blog/compressed_fsm/json_schema.png" style="width: 100%; max-width: 80%; margin-left: auto; margin-right: auto; margin-bottom: auto"></img></p>
<p style="color:gray; text-align: center;">
Figure 2: Example of Constrained Generation Following a JSON Schema
</p>
<p>For local LLMs, there are two major methods to guide the model to generate JSON objects that follow a specific schema.</p>
<h3><a id="method-1-finite-state-machine-based" class="anchor" href="#method-1-finite-state-machine-based" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Method 1: Finite State Machine Based</h3>
<p>This method involves transforming the JSON schema into a regular expression. We can then construct a <a href="https://en.wikipedia.org/wiki/Finite-state_machine">Finite State Machine(FSM)</a> based on the regular expression. The FSM is used to guide the LLM generation. For every state within the FSM, we can calculate the permissible transitions and identify the acceptable next tokens. This allows us to track the current state during decoding and filter out invalid tokens by applying logit bias to the output. You can learn more about this method in the <a href="https://arxiv.org/abs/2307.09702">outlines</a> paper.</p>
<p><img id = "figure3" src="/images/blog/compressed_fsm/method1.png" style="width: 100%; max-width: 100%; margin-left: auto; margin-right: auto; margin-bottom: auto"></img></p>
<p style="color:gray; text-align: center;">
Figure 3: Constrained Decoding based on FSM and Logits Masking. In the first constrained decoding pass, only
<code>age</code> is allowed. In the second pass, as the regex requires digits, both <code>0</code> and <code>1</code> are allowed, but the LLM would sample <code>1</code> with a higher probability.
</p>
<p>The FSM-based method utilizes generalized regular expressions to define the low-level rules, which can be applied to a wide range of grammars, such as JSON schema, IP addresses, and emails.</p>
<p><strong>Limitations:</strong><br>
Since the FSM is constructed at the token level, it can transition the state by only one token at each step. Consequently, it can decode only one token at a time, which results in slow decoding.</p>
<h3><a id="method-2-interleaved-based" class="anchor" href="#method-2-interleaved-based" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Method 2: Interleaved-Based</h3>
<p>Aside from converting the entire JSON schema into a regular expression, another approach is to employ interleaved-based decoding. In this method, a given JSON schema can be broken down into several parts, each containing either a chunked prefill part or a constrained decoding part. These different parts are executed interleavedly by the inference system.
Because the chunked prefill can process multiple tokens in a single forward pass, it is faster than token-by-token decoding.</p>
<p><a href="https://github.com/guidance-ai/guidance?tab=readme-ov-file#guidance-acceleration">Guidance</a> provides a set of syntax rules for interleaved-based decoding, using llama.cpp as a backend.</p>
<p><img src="/images/blog/compressed_fsm/method2.png" style="width: 100%; max-width: 85%; margin-left: auto; margin-right: auto; margin-bottom: auto"></img></p>
<p style="color:gray; text-align: center;">Figure 4: Interleaved JSON Decoding in Guidance</p>
<p><strong>Limitations:</strong></p>
<ul>
<li>The interleaved-based method requires custom syntax, making it less versatile and expressive than individual regular expressions.</li>
<li>It struggles with correctly handling tokenization boundaries due to potential conflicts between the decode and chunked prefill segments.</li>
<li>Frequent communication between the interpreter and the backend brings additional overhead.</li>
</ul>
<h2><a id="our-method-jump-forward-decoding-with-a-compressed-finite-state-machine" class="anchor" href="#our-method-jump-forward-decoding-with-a-compressed-finite-state-machine" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Our Method: Jump-Forward Decoding With a Compressed Finite State Machine</h2>
<p>We can combine the advantages of FSM-based and interleaved-based methods by introducing a new decoding algorithm, <strong>jump-forward</strong> decoding, based on the compressed finite state machine.</p>
<p>During the decoding process guided by the regex converted from the JSON schema, we can predict forthcoming strings when we reach specific junctures:</p>
<ul>
<li>In <a href="#figure3">figure3</a>, at the beginning of decoding, according to the regex, we can anticipate the incoming string to be:<pre><code class="language-json">{
  &quot;name&quot;:
</code></pre>
Then comes the actual decoding part.</li>
<li>Similarly, when the LLM outputs a <code>G</code> while filling in the house attribute of a character, we can confidently predict that the next string will be <code>ryffindor</code>, thereby completing the full string as <code>Gryffindor</code>.</li>
</ul>
<p>That is precisely how the jump-forward decoding algorithm makes decoding faster. In the jump-forward algorithm, we examine the finite state machine of the given regular expression, identify all the singular transition edges, and compress consecutive ones together into <strong>singular paths</strong>. Instead of decoding the singular paths token by token, we can directly prefill (extend) them, jumping forward until the next branching point.</p>
<p><img src="/images/blog/compressed_fsm/compare.png" style="width: 100%; max-width: 100%; margin-left: auto; margin-right: auto; margin-bottom: auto"></img></p>
<p style="color:gray; text-align: center;">Figure 5: Comparison of Jump-Forward Decoding with Compressed FSM and Normal Decoding</p>
<p>The RadixAttention mechanism of SGLang greatly simplifies the implementation of the jump-forward decoding algorithm.
When executing a jump-forward, we can simply terminate the current request and enqueue a new one. The RadixAttention and efficient <strong>extend</strong> primitive in the SGLang runtime will automatically reuse the KV cache of the previous tokens, thereby avoiding redundant computation.</p>
<h3><a id="tokenization-boundary-handling" class="anchor" href="#tokenization-boundary-handling" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tokenization Boundary Handling</h3>
<p>When implementing constrained decoding, it is always tricky to deal with the tokenization boundary, due to the complicated possible mapping between characters and tokens.</p>
<p>During LLM decoding, it might prefer (means with higher probability) to combine multiple characters into a single token.
For instance, when decoding
<code style="color: black; background-color: lightblue;">&quot;Hello&quot;</code>
in the context of JSON decoding, LLMs may output tokens like this:</p>
<p><code style="color: black; background-color: lightblue;">&quot;</code>
<code style="color: black; background-color: lightblue;">He</code>
<code style="color: black; background-color: lightblue;">llo</code>
<code style="color: black; background-color: lightblue;">&quot;,</code></p>
<p>Instead of decoding the last
<code style="color: black; background-color: lightblue;">&quot;</code>
, it always prefers to combine it with a following
<code style="color: black; background-color: lightblue;">,</code>
to form a more frequent token
<code style="color: black; background-color: lightblue;">&quot;,</code>
. This effect may cause some strange behaviors. For example, in the above case, if the regex is set to
<code style="color: black; background-color: lightblue;">&quot;[\w\d\s]*&quot;</code>
(without the last
<code style="color: black; background-color: lightblue;">,</code>
), it can lead to endless decoding because an LLM wants to stop with <code style="color: black; background-color: lightblue;">&quot;,</code> but this token is not allowed.</p>
<p>Moreover, during jump-forward decoding, we've found that different tokenization strategies to the jump-forwarded part may lead to different logit distributions for the subsequent tokens. Simply appending the tokenized jump-forwarded section to the current token sequence might yield unexpected outcomes.</p>
<p>To manage these issues, we propose the following solutions:</p>
<ul>
<li>We have implemented a re-tokenization mechanism during the jump-forward phase. This involves appending the string instead of the tokens, followed by a re-tokenization of the entire text. This method effectively resolves most tokenization issues and results in only a minor increase in computational overhead, approximately 4%.</li>
<li>Prefer the use of a comprehensive regular expression to guide the entire decoding process, rather than employing multiple concatenated regular expressions. This approach ensures that both FSM and LLM are cognizant of the entire decoding process, thereby minimizing boundary-related issues as much as possible.</li>
</ul>
<p>You can also read some additional discussion in this <a href="http://blog.dottxt.co/coalescence.html">blog post</a>.</p>
<h2><a id="benchmark-results" class="anchor" href="#benchmark-results" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Benchmark Results</h2>
<p>We benchmarked our jump-forward decoding on two tasks:</p>
<ul>
<li>Crafting a character's data in JSON format, guided by a brief prompt.</li>
<li>Extracting a city's information from a long document and outputing it in JSON format.</li>
</ul>
<p>We tested llama-7B on an NVIDIA A10 GPU (24GB), and used vllm v0.2.7, guidance v0.1.0, outlines v0.2.5 and llama.cpp v0.2.38(Python binding) . The figure below shows the throughput (using the maximum batch size supported by each system) and latency (with a batch size of 1) of these methods:</p>
<p><img src="/images/blog/compressed_fsm/result.png" style="width: 100%; max-width: 60%; margin-left: auto; margin-right: auto; margin-bottom: auto"></img></p>
<p style="color:gray; text-align: center;">
Figure 6: Benchmark Results
</p>
<p>The results show that SGLang with our decoding algorithm significantly outperforms all other systems.
It can reduce the latency by up to 2x and boost throughput by up to 2.5x.
In the character generation task, even SGLang without Jump-Forward achieves higher throughput than Outlines+vLLM; we suspect this is due to some overhead in Outlines.</p>
<h2><a id="use-cases" class="anchor" href="#use-cases" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Use Cases</h2>
<p>We have been testing this feature with <a href="https://boson.ai/">Boson.ai</a> for two weeks, who are bringing this feature into their production use cases because it guarantees robust response with higher decoding throughput.</p>
<p>Additionally, another user used this feature to extract structured information from images by utilizing the vision language model, LLaVA.</p>
<p><img src="/images/blog/compressed_fsm/llava_demo.gif" style="width: 100%; max-width: 100%; margin-left: auto; margin-right: auto; margin-bottom: auto"></img></p>
<p style="color:gray; text-align: center;">
Figure 7: Extracting structured information from an image using SGLang and LLaVA
</p>
<h2><a id="link" class="anchor" href="#link" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Link</h2>
<ul>
<li>You can try this feature now in <a href="https://github.com/sgl-project/sglang/tree/main?tab=readme-ov-file#json-decoding">SGLang</a>.</li>
<li>Benchmark code is available <a href="https://github.com/sgl-project/sglang/tree/main/benchmark/json_jump_forward">here</a>.</li>
<li>We thank <a href="https://github.com/outlines-dev/outlines">outlines</a> for open-sourcing its FSM implementation. We built our compressed FSM based on it.</li>
</ul>
</div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"Fast JSON Decoding for Local LLMs with Compressed Finite State Machine","author":"Liangsheng Yin, Ying Sheng, Lianmin Zheng","date":"Feb 5, 2024","previewImg":"/images/blog/compressed_fsm/demo.gif"},"content":"\nConstraining an LLM to consistently generate valid JSON or YAML that adheres to a specific schema is a critical feature for many applications.\nIn this blog post, we introduce an optimization that significantly accelerates this type of constrained decoding. Our approach utilizes a compressed finite state machine and is compatible with any regular expression, thereby accommodating any JSON or YAML schema.\nDistinct from existing systems that decode one token at one step, our method analyzes the finite state machine of a regular expression, compresses singular transition paths, and decodes \u003cu\u003emultiple tokens in a single step\u003c/u\u003e whenever feasible. In comparison to state-of-the-art systems (guidance + llama.cpp, outlines + vLLM), our method can reduce the latency by up to 2x and boost throughput by up to 2.5x.\nThis optimization also makes constrained decoding even faster than normal deocding.\nYou can try it now on [SGLang](https://github.com/sgl-project/sglang/tree/main?tab=readme-ov-file#json-decoding).\n\n\u003cimg src=\"/images/blog/compressed_fsm/demo.gif\" style=\"width: 100%; max-width: 100%; margin-left: auto; margin-right: auto; margin-bottom: auto\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003e\nFigure 1: Comparison of SGLang and Outlines + vLLM in JSON Decoding\n\u003c/p\u003e\n\n## Background\n\n[JSON](https://en.wikipedia.org/wiki/JSON) is one of the most important formats for data interchange. Requiring LLMs to always generate valid JSON can render the output of the LLM easily parsable in a structured manner. Recognizing its significance, OpenAI introduced the [JSON mode](https://platform.openai.com/docs/guides/text-generation/json-mode), which constrains the model to always return a valid JSON object. However, more  fine-grained control is often needed to ensure that the generated JSON object adheres to a specific [schema](https://json-schema.org/), such as\n\n\u003cimg src=\"/images/blog/compressed_fsm/json_schema.png\" style=\"width: 100%; max-width: 80%; margin-left: auto; margin-right: auto; margin-bottom: auto\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003e\nFigure 2: Example of Constrained Generation Following a JSON Schema\n\u003c/p\u003e\n\nFor local LLMs, there are two major methods to guide the model to generate JSON objects that follow a specific schema.\n\n### Method 1: Finite State Machine Based\n\nThis method involves transforming the JSON schema into a regular expression. We can then construct a [Finite State Machine(FSM)](https://en.wikipedia.org/wiki/Finite-state_machine) based on the regular expression. The FSM is used to guide the LLM generation. For every state within the FSM, we can calculate the permissible transitions and identify the acceptable next tokens. This allows us to track the current state during decoding and filter out invalid tokens by applying logit bias to the output. You can learn more about this method in the [outlines](https://arxiv.org/abs/2307.09702) paper.\n\n\u003cimg id = \"figure3\" src=\"/images/blog/compressed_fsm/method1.png\" style=\"width: 100%; max-width: 100%; margin-left: auto; margin-right: auto; margin-bottom: auto\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003e\nFigure 3: Constrained Decoding based on FSM and Logits Masking. In the first constrained decoding pass, only\n\u003ccode\u003eage\u003c/code\u003e is allowed. In the second pass, as the regex requires digits, both \u003ccode\u003e0\u003c/code\u003e and \u003ccode\u003e1\u003c/code\u003e are allowed, but the LLM would sample \u003ccode\u003e1\u003c/code\u003e with a higher probability.\n\u003c/p\u003e\n\nThe FSM-based method utilizes generalized regular expressions to define the low-level rules, which can be applied to a wide range of grammars, such as JSON schema, IP addresses, and emails.\n\n**Limitations:**  \nSince the FSM is constructed at the token level, it can transition the state by only one token at each step. Consequently, it can decode only one token at a time, which results in slow decoding.\n\n### Method 2: Interleaved-Based\n\nAside from converting the entire JSON schema into a regular expression, another approach is to employ interleaved-based decoding. In this method, a given JSON schema can be broken down into several parts, each containing either a chunked prefill part or a constrained decoding part. These different parts are executed interleavedly by the inference system.\nBecause the chunked prefill can process multiple tokens in a single forward pass, it is faster than token-by-token decoding.\n\n[Guidance](https://github.com/guidance-ai/guidance?tab=readme-ov-file#guidance-acceleration) provides a set of syntax rules for interleaved-based decoding, using llama.cpp as a backend.\n\n\u003cimg src=\"/images/blog/compressed_fsm/method2.png\" style=\"width: 100%; max-width: 85%; margin-left: auto; margin-right: auto; margin-bottom: auto\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003eFigure 4: Interleaved JSON Decoding in Guidance\u003c/p\u003e\n\n**Limitations:**  \n- The interleaved-based method requires custom syntax, making it less versatile and expressive than individual regular expressions.\n- It struggles with correctly handling tokenization boundaries due to potential conflicts between the decode and chunked prefill segments.\n- Frequent communication between the interpreter and the backend brings additional overhead.\n\n## Our Method: Jump-Forward Decoding With a Compressed Finite State Machine\n\nWe can combine the advantages of FSM-based and interleaved-based methods by introducing a new decoding algorithm, **jump-forward** decoding, based on the compressed finite state machine.\n\nDuring the decoding process guided by the regex converted from the JSON schema, we can predict forthcoming strings when we reach specific junctures:\n\n- In [figure3](#figure3), at the beginning of decoding, according to the regex, we can anticipate the incoming string to be:\n    ```json\n    {\n      \"name\":\n    ```\n    Then comes the actual decoding part.\n- Similarly, when the LLM outputs a `G` while filling in the house attribute of a character, we can confidently predict that the next string will be `ryffindor`, thereby completing the full string as `Gryffindor`.\n\nThat is precisely how the jump-forward decoding algorithm makes decoding faster. In the jump-forward algorithm, we examine the finite state machine of the given regular expression, identify all the singular transition edges, and compress consecutive ones together into **singular paths**. Instead of decoding the singular paths token by token, we can directly prefill (extend) them, jumping forward until the next branching point.\n\n\u003cimg src=\"/images/blog/compressed_fsm/compare.png\" style=\"width: 100%; max-width: 100%; margin-left: auto; margin-right: auto; margin-bottom: auto\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003eFigure 5: Comparison of Jump-Forward Decoding with Compressed FSM and Normal Decoding\u003c/p\u003e\n\nThe RadixAttention mechanism of SGLang greatly simplifies the implementation of the jump-forward decoding algorithm.\nWhen executing a jump-forward, we can simply terminate the current request and enqueue a new one. The RadixAttention and efficient **extend** primitive in the SGLang runtime will automatically reuse the KV cache of the previous tokens, thereby avoiding redundant computation.\n\n### Tokenization Boundary Handling\n\nWhen implementing constrained decoding, it is always tricky to deal with the tokenization boundary, due to the complicated possible mapping between characters and tokens.\n\n\nDuring LLM decoding, it might prefer (means with higher probability) to combine multiple characters into a single token.\nFor instance, when decoding\n\u003ccode style=\"color: black; background-color: lightblue;\"\u003e\"Hello\"\u003c/code\u003e\nin the context of JSON decoding, LLMs may output tokens like this:\n\n\u003ccode style=\"color: black; background-color: lightblue;\"\u003e\"\u003c/code\u003e\n\u003ccode style=\"color: black; background-color: lightblue;\"\u003eHe\u003c/code\u003e\n\u003ccode style=\"color: black; background-color: lightblue;\"\u003ello\u003c/code\u003e\n\u003ccode style=\"color: black; background-color: lightblue;\"\u003e\",\u003c/code\u003e\n\nInstead of decoding the last\n\u003ccode style=\"color: black; background-color: lightblue;\"\u003e\"\u003c/code\u003e\n, it always prefers to combine it with a following \n\u003ccode style=\"color: black; background-color: lightblue;\"\u003e,\u003c/code\u003e\nto form a more frequent token\n\u003ccode style=\"color: black; background-color: lightblue;\"\u003e\",\u003c/code\u003e\n. This effect may cause some strange behaviors. For example, in the above case, if the regex is set to\n\u003ccode style=\"color: black; background-color: lightblue;\"\u003e\"[\\w\\d\\s]*\"\u003c/code\u003e\n(without the last \n\u003ccode style=\"color: black; background-color: lightblue;\"\u003e,\u003c/code\u003e\n), it can lead to endless decoding because an LLM wants to stop with \u003ccode style=\"color: black; background-color: lightblue;\"\u003e\",\u003c/code\u003e but this token is not allowed.\n\nMoreover, during jump-forward decoding, we've found that different tokenization strategies to the jump-forwarded part may lead to different logit distributions for the subsequent tokens. Simply appending the tokenized jump-forwarded section to the current token sequence might yield unexpected outcomes.\n\nTo manage these issues, we propose the following solutions:\n- We have implemented a re-tokenization mechanism during the jump-forward phase. This involves appending the string instead of the tokens, followed by a re-tokenization of the entire text. This method effectively resolves most tokenization issues and results in only a minor increase in computational overhead, approximately 4\\%.\n- Prefer the use of a comprehensive regular expression to guide the entire decoding process, rather than employing multiple concatenated regular expressions. This approach ensures that both FSM and LLM are cognizant of the entire decoding process, thereby minimizing boundary-related issues as much as possible.\n\nYou can also read some additional discussion in this [blog post](http://blog.dottxt.co/coalescence.html).\n\n## Benchmark Results\n\nWe benchmarked our jump-forward decoding on two tasks:\n\n- Crafting a character's data in JSON format, guided by a brief prompt.\n- Extracting a city's information from a long document and outputing it in JSON format.\n\nWe tested llama-7B on an NVIDIA A10 GPU (24GB), and used vllm v0.2.7, guidance v0.1.0, outlines v0.2.5 and llama.cpp v0.2.38(Python binding) . The figure below shows the throughput (using the maximum batch size supported by each system) and latency (with a batch size of 1) of these methods:\n\n\u003cimg src=\"/images/blog/compressed_fsm/result.png\" style=\"width: 100%; max-width: 60%; margin-left: auto; margin-right: auto; margin-bottom: auto\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003e\nFigure 6: Benchmark Results\n\u003c/p\u003e\n\nThe results show that SGLang with our decoding algorithm significantly outperforms all other systems.\nIt can reduce the latency by up to 2x and boost throughput by up to 2.5x.\nIn the character generation task, even SGLang without Jump-Forward achieves higher throughput than Outlines+vLLM; we suspect this is due to some overhead in Outlines.\n\n## Use Cases\n\nWe have been testing this feature with [Boson.ai](https://boson.ai/) for two weeks, who are bringing this feature into their production use cases because it guarantees robust response with higher decoding throughput.\n\nAdditionally, another user used this feature to extract structured information from images by utilizing the vision language model, LLaVA.\n\n\u003cimg src=\"/images/blog/compressed_fsm/llava_demo.gif\" style=\"width: 100%; max-width: 100%; margin-left: auto; margin-right: auto; margin-bottom: auto\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003e\nFigure 7: Extracting structured information from an image using SGLang and LLaVA\n\u003c/p\u003e\n\n## Link\n- You can try this feature now in [SGLang](https://github.com/sgl-project/sglang/tree/main?tab=readme-ov-file#json-decoding).\n- Benchmark code is available [here](https://github.com/sgl-project/sglang/tree/main/benchmark/json_jump_forward).\n- We thank [outlines](https://github.com/outlines-dev/outlines) for open-sourcing its FSM implementation. We built our compressed FSM based on it.\n","slug":"2024-02-05-compressed-fsm"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"2024-02-05-compressed-fsm"},"buildId":"QR8Ie-cIm8I8VX1A2KzTJ","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>