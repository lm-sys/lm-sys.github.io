<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/styles/atom-one-light.min.css"/><title>Does style matter? Disentangling style and substance in Chatbot Arena | LMSYS Org</title><meta name="title" content="Does style matter? Disentangling style and substance in Chatbot Arena | LMSYS Org"/><meta property="og:title" content="Does style matter? Disentangling style and substance in Chatbot Arena | LMSYS Org"/><meta name="twitter:title" content="Does style matter? Disentangling style and substance in Chatbot Arena | LMSYS Org"/><meta name="description" content="&lt;p&gt;Why is GPT-4o-mini so good? Why does Claude rank so low, when anecdotal experience suggests otherwise?&lt;/p&gt;
&lt;p&gt;We have answers for you. We controlled for t..."/><meta property="og:description" content="&lt;p&gt;Why is GPT-4o-mini so good? Why does Claude rank so low, when anecdotal experience suggests otherwise?&lt;/p&gt;
&lt;p&gt;We have answers for you. We controlled for t..."/><meta name="twitter:description" content="&lt;p&gt;Why is GPT-4o-mini so good? Why does Claude rank so low, when anecdotal experience suggests otherwise?&lt;/p&gt;
&lt;p&gt;We have answers for you. We controlled for t..."/><meta property="og:image" content="https://lmsys.org/images/blog/style_control/logo.png"/><meta name="twitter:image" content="https://lmsys.org/images/blog/style_control/logo.png"/><meta name="twitter:image:alt" content="The text: LLMSYS Org, Large Model Systems Organization."/><meta property="og:type" content="website"/><meta property="og:url" content="https://lmsys.org/blog/2024-08-28-style-control"/><meta name="twitter:url" content="https://lmsys.org/blog/2024-08-28-style-control"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1d1d1f"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.jpeg"/><link rel="icon" href="/favicon.jpeg" type="image/jpg"/><meta name="next-head-count" content="20"/><script src="/mathjax.js" defer=""></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js" defer=""></script><link rel="preload" href="/_next/static/css/664049df48ded145.css" as="style"/><link rel="stylesheet" href="/_next/static/css/664049df48ded145.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-5289d222aec181f4.js" defer=""></script><script src="/_next/static/chunks/286-48ebbaba72d91976.js" defer=""></script><script src="/_next/static/chunks/807-a4eae1dfa8bfbe9f.js" defer=""></script><script src="/_next/static/chunks/138-efd6d72a198878c6.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-c9fe776063d24120.js" defer=""></script><script src="/_next/static/syzLuWNJ0e7YclZ1XB3I3/_buildManifest.js" defer=""></script><script src="/_next/static/syzLuWNJ0e7YclZ1XB3I3/_ssgManifest.js" defer=""></script><script src="/_next/static/syzLuWNJ0e7YclZ1XB3I3/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-sky md:text-paper md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LMSYS ORG</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/blog/">Blog</a><a href="/about/">About</a><a href="/donations/">Donations</a><a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">Chatbot Arena (graduated)</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.gg/HSWAKCrnFx" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1d1d1f;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/blog/">Blog</a></p><p><a href="/about/">About</a></p><p><a href="/donations/">Donations</a></p><p><a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">Chatbot Arena (graduated)</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.gg/HSWAKCrnFx" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-sky grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5" lang="en"><h1 lang="en" style="hyphens:auto" class="text-4xl md:text-4xl w-full font-bold break-words">Does style matter? Disentangling style and substance in Chatbot Arena</h1><p class="text-xl pt-2 pb-2">by: <!-- -->Tianle Li*, Anastasios Angelopoulos*, Wei-Lin Chiang*<!-- -->,<!-- --> <!-- -->Aug 29, 2024<!-- --></p><hr/><div class="pt-2 article"><p>Why is GPT-4o-mini so good? Why does Claude rank so low, when anecdotal experience suggests otherwise?</p>
<p>We have answers for you. We controlled for the effect of length and markdown, and indeed, <em>the ranking changed</em>. This is just a first step towards our larger goal of disentangling <strong>substance</strong> and <strong>style</strong> in Chatbot Arena leaderboard.</p>
<p><strong>Check out the results below!</strong> Style indeed has a strong effect on models’ performance in the leaderboard. This makes sense—from the perspective of human preference, it’s not just what you say, but how you say it. But now, we have a way of <em>separating</em> the effect of writing style from the content, so you can see both effects individually.</p>
<p>When controlling for length and style, we found noticeable shifts in the ranking. GPT-4o-mini and Grok-2-mini drop below most frontier models, and Claude 3.5 Sonnet, Opus, and Llama-3.1-405B rise substantially. In the Hard Prompt subset, Claude 3.5 Sonnet ties for #1 with chatgpt-4o-latest and Llama-3.1-405B climbs to #3. We are looking forward to seeing what the community does with this new tool for disaggregating style and substance!</p>
<h3><a id="overall-ranking--style-control" class="anchor" href="#overall-ranking--style-control" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overall Ranking + Style Control</h3>
<p><img src="/images/blog/style_control/comparison_overall.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 80%"></img></p>
<p style="color:gray; text-align: center;">Figure 1. Overall Chatbot Arena ranking vs Overall Chatbot Arena ranking where answer length, markdown header count, markdown bold count, and markdown list element count are being “controlled”.</p>
<h3><a id="hard-prompt-ranking--style-control" class="anchor" href="#hard-prompt-ranking--style-control" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hard Prompt Ranking + Style Control</h3>
<p><img src="/images/blog/style_control/comparison_hard.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 80%"></img></p>
<p style="color:gray; text-align: center;">Figure 2. Hard Prompt category ranking vs Hard Prompt category ranking where answer length, markdown header count, markdown bold count, and markdown list element count are being “controlled”.</p>
<h3><a id="full-leaderboard-with-style-control" class="anchor" href="#full-leaderboard-with-style-control" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Full Leaderboard with Style Control</h3>
<p><img src="/images/blog/style_control/arena_leaderboard.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 90%"></img></p>
<p>Please find the below links to leaderboard and colab notebook. We will be rolling out style control soon to all the categories. Stay tuned!</p>
<ul>
<li>Leaderboard <a href="https://lmarena.ai/?leaderboard">link</a></li>
<li>Colab <a href="https://colab.research.google.com/drive/19VPOril2FjCX34lJoo7qn4r6adgKLioY#scrollTo=C4xnVybEy0OO">link</a></li>
</ul>
<h2><a id="methodology" class="anchor" href="#methodology" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Methodology</h2>
<p><strong>High-Level Idea.</strong> The goal here is to understand the effect of <em>style</em> vs <em>substance</em> on the Arena Score. Consider models A and B. Model A is great at producing code, factual and unbiased answers, etc., but it outputs short and terse responses. Model B is not so great on substance (e.g., correctness), but it outputs great markdown, and gives long, detailed, flowery responses. Which is better, model A, or model B?</p>
<p>The answer is not one dimensional. Model A is better on substance, and Model B is better on style. Ideally, we would have a way of teasing apart this distinction: capturing how much of the model’s Arena Score is due to substance or style.</p>
<p>Our methodology is a first step towards this goal. We explicitly model style as an independent variable in our Bradley-Terry regression. For example, we added length as a feature—just like each model, the length difference has its <em>own</em> Arena Score! By doing this, we expect that the Arena Score of each model will reflect its strength, controlled for the effect of length.</p>
<p>Please read below for the technical details. We also controlled not just for length, but also a few other style features. As a first version, we propose controlling</p>
<ol>
<li>Answer token length</li>
<li>Number of markdown headers</li>
<li>Number of markdown bold elements</li>
<li>Number of markdown lists</li>
</ol>
<p>We publicly release our data with vote and style elements and code on <a href="https://colab.research.google.com/drive/19VPOril2FjCX34lJoo7qn4r6adgKLioY#scrollTo=dYANZPG_8a9N">google colab</a>! You can try out experimenting with style control now. More improvements to come, and please reach out if you want to help contribute!</p>
<p><strong>Background.</strong> To produce the results above, we controlled for the effect of style by adding extra “style features” into our Bradley-Terry regression. This is a <a href="https://en.wikipedia.org/wiki/Controlling_for_a_variable">standard technique</a> in statistics, and has been recently used in LLM evaluations [1]. Additionally, there are studies suggesting potential bias for “pretty” and more detailed responses in humans [2, 3]. The idea is that, by including any confounding variables (e.g. response length) in the regression, we can attribute any increase in strength to the confounder, as opposed to the model. Then, the Bradley-Terry coefficient will be more reflective of the model’s intrinsic ability, as opposed to possible confounders. The definition of a confounder is to some extent up to our interpretation; as our style features, we use the (normalized) difference in response lengths, the number of markdown headers, and the number of lists.</p>
<p>More formally, consider vectors $X_1, \ldots, X_n \in \mathbb{R}^M$ and $Y_1, \ldots, Y_n \in {0,1}$, where $n$ is the number of battles and $M$ is the number of models.</p>
<p>For every $i \in [n]$, We have that $X_{i,m}=1$ only if model $m \in [M]$ is the model shown in the left-hand side in Chatbot Arena, and $X_{i,m}=-1$ only if it is shown on the right. That is, $X_i$ is a vector with two nonzero elements. The outcome $Y_i$ takes the value $Y_i=1$ if the left-hand model wins, and $Y_i=0$ otherwise.</p>
<p>The standard method for computing the Arena Score (i.e., the Bradley-Terry coefficients, which we formerly called the Elo score) is to run a logistic regression of $Y_i$ onto $X_i$. That is, for every model $m$, we associate a scalar $\hat{\beta}_m$ that describes its strength, and the vector $\hat{\beta}$ is determined by solving the following logistic regression:</p>
<p>$$\hat{\beta} = \arg \min_{\beta \in \mathbb{R}^M} \frac{1}{n}\sum\limits_{i=1}^n \mathsf{BCELoss}(\mathsf{sigmoid}(X_i^\top \beta), Y_i)$$</p>
<p>where  $\mathsf{BCELoss}$ represents the binary cross-entropy loss. (In practice, we also reweight this objective to handle non-uniform model sampling, but let’s ignore that for now.)</p>
<h2><a id="style-control" class="anchor" href="#style-control" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Style Control</h2>
<p>Now, for every battle $i \in [n]$, let’s say that in addition to $X_i$ that we observe some additional style features, $Z_i \in \mathbb{R}^S$. These style features can be as simple or complicated as you want. For example, $Z_i$ could just be the difference in response lengths of the two models, in which case $S=1$. Or, we could have $S&gt;1$ and include other style-related features, for example, the number of markdown headers, common words associated with refusal, or even style features that are automatically extracted by a model!</p>
<p>Here, we define each style feature as
$$\text{normalize }\left(\frac{\text{feature}_A - \text{feature}_B}{\text{feature}_A + \text{feature}_B}\right)$$</p>
<p>For example, the first new feature, token length difference between answer A and answer B, would be expressed as
$$\text{normalize }\left(\frac{\text{length}_A - \text{length}_B}{\text{length}_A + \text{length}_B}\right)$$</p>
<p>We divide the difference by the sum of both answers' token length to make the length difference proportional to the pairwise answer token lengths. An answer with 500 tokens is roughly equal in length to an answer with 520 tokens, while an answer with 20 tokens is very different from an answer with 40 tokens, even though the difference is 20 tokens for both scenarios. Alternatively, AlpacaEval LC uses the following normalization technique.</p>
<p>$$\tanh\left(\frac{\text{feature}_A - \text{feature}_B)}{\sigma(\text{feature}_A - \text{feature}_B)}\right)$$.</p>
<p>The idea of style control is very basic. We perform the same logistic regression as before, but with some extra, additive style coefficients:
$$\hat{\beta}, \hat{\gamma} = \arg \min_{\beta \in \mathbb{R}^M, \gamma \in \mathbb{R}^S} \frac{1}{n}\sum\limits_{i=1}^n \mathsf{BCELoss}(\mathsf{sigmoid}(X_i^\top \beta + Z_i^{\top}\gamma), Y_i).$$
We refer to the results $\hat{\beta}$ and $\hat{\gamma}$ as the “model coefficients” and the “style coefficients” respectively. The model coefficients have the same interpretation as before; however, they are controlled for the effect of style, which is explicitly modeled by the style coefficients!</p>
<p>When the style coefficients are big, that means that the style feature has a big effect on the response. To define “big”, you need to properly normalize the style coefficients so they can be compared. All in all, when analyzing the style coefficients, we found that length was the dominant style factor. All other markdown effects are second order.</p>
<p>We report the following coefficient for each style attribute across different methods of controlling the style.</p>
<table style="border-collapse: collapse; width: 100%;">
  <tr>
    <th style="text-align: center; padding: 8px;"></th>
    <th style="text-align: center; padding: 8px;">Length</th>
    <th style="text-align: center; padding: 8px;">Markdown List</th>
    <th style="text-align: center; padding: 8px;">Markdown Header</th>
    <th style="text-align: center; padding: 8px;">Markdown Bold</th>
  </tr>
<tr>
    <td style="text-align: left; padding: 8px;">Control Both</td>
    <td style="text-align: center; padding: 8px;">0.249</td>
    <td style="text-align: center; padding: 8px;">0.031</td>
    <td style="text-align: center; padding: 8px;">0.024</td>
    <td style="text-align: center; padding: 8px;">0.019</td>
  </tr>
<tr>
    <td style="text-align: left; padding: 8px;">Control Markdown Only</td>
    <td style="text-align: center; padding: 8px;">-</td>
    <td style="text-align: center; padding: 8px;">0.111</td>
    <td style="text-align: center; padding: 8px;">0.044</td>
    <td style="text-align: center; padding: 8px;">0.056</td>
  </tr>
<tr>
    <td style="text-align: left; padding: 8px;">Control Length Only</td>
    <td style="text-align: center; padding: 8px;">0.267</td>
    <td style="text-align: center; padding: 8px;">-</td>
    <td style="text-align: center; padding: 8px;">-</td>
    <td style="text-align: center; padding: 8px;">-</td>
  </tr>
</table>
<h2><a id="ablation" class="anchor" href="#ablation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Ablation</h2>
<p>Next, we compare the ranking changes between controlling for answer length only, markdown element only, and both. We present the Chatbot Arena Overall table first.</p>
<table style="border-collapse: collapse; width: 100%;">
  <tr>
    <th style="text-align: left; padding: 8px; width: 30%;">Model</th>
    <th style="text-align: center; padding: 8px; width: 25%;">Rank Diff (Length Only)</th>
    <th style="text-align: center; padding: 8px; width: 25%;">Rank Diff (Markdown Only)</th>
    <th style="text-align: center; padding: 8px; width: 20%;">Rank Diff (Both)</th>
  </tr>
<tr>
    <td style="text-align: left; padding: 8px;">chatgpt-4o-latest</td>
    <td style="text-align: center; padding: 8px;">1->1</td>
    <td style="text-align: center; padding: 8px;">1->1</td>
    <td style="text-align: center; padding: 8px;">1->1</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-pro-exp-0827</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-pro-exp-0801</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4o-2024-05-13</td>
    <td style="text-align: center; padding: 8px; color: green;">5->3</td>
    <td style="text-align: center; padding: 8px; color: green;">5->3</td>
    <td style="text-align: center; padding: 8px; color: green;">5->2</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">claude-3-5-sonnet-20240620</td>
    <td style="text-align: center; padding: 8px; color: green;">6->5</td>
    <td style="text-align: center; padding: 8px; color: green;">6->4</td>
    <td style="text-align: center; padding: 8px; color: green;">6->4</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-advanced-0514</td>
    <td style="text-align: center; padding: 8px; color: green;">7->5</td>
    <td style="text-align: center; padding: 8px; color: red;">7->8</td>
    <td style="text-align: center; padding: 8px; color: green;">7->6</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">grok-2-2024-08-13</td>
    <td style="text-align: center; padding: 8px; color: red;">2->4</td>
    <td style="text-align: center; padding: 8px; color: red;">2->4</td>
    <td style="text-align: center; padding: 8px; color: red;">2->5</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">llama-3.1-405b-instruct</td>
    <td style="text-align: center; padding: 8px;">6->6</td>
    <td style="text-align: center; padding: 8px; color: green;">6->4</td>
    <td style="text-align: center; padding: 8px;">6->6</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4o-2024-08-06</td>
    <td style="text-align: center; padding: 8px; color: green;">7->6</td>
    <td style="text-align: center; padding: 8px; color: red;">7->8</td>
    <td style="text-align: center; padding: 8px; color: green;">7->6</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4-turbo-2024-04-09</td>
    <td style="text-align: center; padding: 8px; color: green;">11->8</td>
    <td style="text-align: center; padding: 8px; color: green;">11->8</td>
    <td style="text-align: center; padding: 8px; color: green;">11->9</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">claude-3-opus-20240229</td>
    <td style="text-align: center; padding: 8px; color: green;">16->14</td>
    <td style="text-align: center; padding: 8px; color: green;">16->8</td>
    <td style="text-align: center; padding: 8px; color: green;">16->10</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-pro-api-0514</td>
    <td style="text-align: center; padding: 8px; color: green;">10->8</td>
    <td style="text-align: center; padding: 8px; color: red;">10->13</td>
    <td style="text-align: center; padding: 8px;">10->10</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-flash-exp-0827</td>
    <td style="text-align: center; padding: 8px; color: red;">6->8</td>
    <td style="text-align: center; padding: 8px; color: red;">6->9</td>
    <td style="text-align: center; padding: 8px; color: red;">6->9</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4-1106-preview</td>
    <td style="text-align: center; padding: 8px; color: green;">16->14</td>
    <td style="text-align: center; padding: 8px; color: green;">16->8</td>
    <td style="text-align: center; padding: 8px; color: green;">16->11</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;"><strong>gpt-4o-mini-2024-07-18</strong></td>
    <td style="text-align: center; padding: 8px; color: red;">6->8</td>
    <td style="text-align: center; padding: 8px; color: red;">6->11</td>
    <td style="text-align: center; padding: 8px; color: red;">6->11</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4-0125-preview</td>
    <td style="text-align: center; padding: 8px; color: green;">17->14</td>
    <td style="text-align: center; padding: 8px; color: green;">17->12</td>
    <td style="text-align: center; padding: 8px; color: green;">17->13</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">mistral-large-2407</td>
    <td style="text-align: center; padding: 8px; color: green;">16->14</td>
    <td style="text-align: center; padding: 8px; color: green;">16->13</td>
    <td style="text-align: center; padding: 8px; color: green;">16->13</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">athene-70b-0725</td>
    <td style="text-align: center; padding: 8px;">16->16</td>
    <td style="text-align: center; padding: 8px; color: red;">16->17</td>
    <td style="text-align: center; padding: 8px; color: red;">16->17</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;"><strong>grok-2-mini-2024-08-13</strong></td>
    <td style="text-align: center; padding: 8px; color: red;">6->15</td>
    <td style="text-align: center; padding: 8px; color: red;">6->15</td>
    <td style="text-align: center; padding: 8px; color: red;">6->18</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-pro-api-0409-preview</td>
    <td style="text-align: center; padding: 8px; color: red;">11->16</td>
    <td style="text-align: center; padding: 8px; color: red;">11->21</td>
    <td style="text-align: center; padding: 8px; color: red;">11->18</td>
  </tr>
</table>
<p>We also perform the same comparison on Chatbot Arena Hard Prompt Category.</p>
<table style="border-collapse: collapse; width: 100%;">
  <tr>
    <th style="text-align: left; padding: 8px; width: 30%;">Model</th>
    <th style="text-align: center; padding: 8px; width: 25%;">Rank Diff (Length Only)</th>
    <th style="text-align: center; padding: 8px; width: 25%;">Rank Diff (Markdown Only)</th>
    <th style="text-align: center; padding: 8px; width: 20%;">Rank Diff (Both)</th>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">chatgpt-4o-latest</td>
    <td style="text-align: center; padding: 8px;">1->1</td>
    <td style="text-align: center; padding: 8px;">1->1</td>
    <td style="text-align: center; padding: 8px;">1->1</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;"><strong>claude-3-5-sonnet-20240620</strong></td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px; color: green;">2->1</td>
    <td style="text-align: center; padding: 8px; color: green;">2->1</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-pro-exp-0827</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px; color: green;">2->1</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-pro-exp-0801</td>
    <td style="text-align: center; padding: 8px; color: red;">2->3</td>
    <td style="text-align: center; padding: 8px; color: red;">2->3</td>
    <td style="text-align: center; padding: 8px; color: red;">2->3</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4o-2024-05-13</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px;">2->2</td>
    <td style="text-align: center; padding: 8px; color: red;">2->3</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">llama-3.1-405b-instruct</td>
    <td style="text-align: center; padding: 8px;">4->4</td>
    <td style="text-align: center; padding: 8px; color: green;">4->2</td>
    <td style="text-align: center; padding: 8px; color: green;">4->3</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">grok-2-2024-08-13</td>
    <td style="text-align: center; padding: 8px; color: red;">2->3</td>
    <td style="text-align: center; padding: 8px; color: red;">2->3</td>
    <td style="text-align: center; padding: 8px; color: red;">2->4</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-flash-exp-0827</td>
    <td style="text-align: center; padding: 8px;">4->4</td>
    <td style="text-align: center; padding: 8px; color: red;">4->6</td>
    <td style="text-align: center; padding: 8px;">4->4</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-1.5-pro-api-0514</td>
    <td style="text-align: center; padding: 8px; color: green;">7->6</td>
    <td style="text-align: center; padding: 8px;">7->7</td>
    <td style="text-align: center; padding: 8px;">7->7</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4o-2024-08-06</td>
    <td style="text-align: center; padding: 8px;">4->4</td>
    <td style="text-align: center; padding: 8px; color: red;">4->6</td>
    <td style="text-align: center; padding: 8px;">4->4</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gemini-advanced-0514</td>
    <td style="text-align: center; padding: 8px; color: green;">9->7</td>
    <td style="text-align: center; padding: 8px; color: green;">9->7</td>
    <td style="text-align: center; padding: 8px; color: green;">9->7</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">claude-3-opus-20240229</td>
    <td style="text-align: center; padding: 8px; color: green;">14->7</td>
    <td style="text-align: center; padding: 8px; color: green;">14->7</td>
    <td style="text-align: center; padding: 8px; color: green;">14->7</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">mistral-large-2407</td>
    <td style="text-align: center; padding: 8px;">7->7</td>
    <td style="text-align: center; padding: 8px; color: green;">7->6</td>
    <td style="text-align: center; padding: 8px;">7->7</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4-1106-preview</td>
    <td style="text-align: center; padding: 8px; color: green;">11->10</td>
    <td style="text-align: center; padding: 8px; color: green;">11->7</td>
    <td style="text-align: center; padding: 8px; color: green;">11->7</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4-turbo-2024-04-09</td>
    <td style="text-align: center; padding: 8px; color: green;">9->7</td>
    <td style="text-align: center; padding: 8px; color: green;">9->7</td>
    <td style="text-align: center; padding: 8px; color: green;">9->7</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">athene-70b-0725</td>
    <td style="text-align: center; padding: 8px; color: green;">11->7</td>
    <td style="text-align: center; padding: 8px; color: green;">11->8</td>
    <td style="text-align: center; padding: 8px; color: green;">11->7</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4o-mini-2024-07-18</td>
    <td style="text-align: center; padding: 8px; color: red;">4->7</td>
    <td style="text-align: center; padding: 8px; color: red;">4->7</td>
    <td style="text-align: center; padding: 8px; color: red;">4->11</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">gpt-4-0125-preview</td>
    <td style="text-align: center; padding: 8px; color: green;">15->14</td>
    <td style="text-align: center; padding: 8px; color: green;">15->10</td>
    <td style="text-align: center; padding: 8px; color: green;">15->13</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">grok-2-mini-2024-08-13</td>
    <td style="text-align: center; padding: 8px; color: red;">5->12</td>
    <td style="text-align: center; padding: 8px; color: red;">5->8</td>
    <td style="text-align: center; padding: 8px; color: red;">5->13</td>
  </tr>
  <tr>
    <td style="text-align: left; padding: 8px;">deepseek-coder-v2-0724</td>
    <td style="text-align: center; padding: 8px; color: green;">16->14</td>
    <td style="text-align: center; padding: 8px; color: green;">16->13</td>
    <td style="text-align: center; padding: 8px; color: green;">16->14</td>
  </tr>
</table>
<h2><a id="limitations-and-future-work" class="anchor" href="#limitations-and-future-work" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Limitations and Future Work</h2>
<p>We want to continue building a pipeline to disentangle style and substance in the arena. Although controlling for style is a big step forward, our analysis is still <em>observational</em>. There are possible unobserved confounders such as positive correlation between length and substantive quality that are <em>not</em> accounted for by our study. For example, well-known example of a possible unobserved confounder that might positively impact both length and quality is a chain-of-thought explanation for a reasoning question.</p>
<p>To address these limitations, we are looking forward to implementing <em>causal inference</em> in our pipeline, and running prospective randomized trials to assess the effect of length, markdown, and more. Our pipeline for style control will be changing as we continue to improve our system and refine the analysis. Stay tuned, and let us know if you want to help!</p>
<h2><a id="reference" class="anchor" href="#reference" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reference</h2>
<p>[1] Dubois et al. “Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators”, arXiv preprint</p>
<p>[2] Chen et al. “Humans or LLMs as the Judge? A Study on Judgement Bias”, arXiv preprint</p>
<p>[3] Park et al. “Disentangling Length from Quality in Direct Preference Optimization”, arXiv preprint</p>
<h2><a id="citation" class="anchor" href="#citation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Citation</h2>
<pre><code class="hljs">@misc{chiang2024chatbot,
    title={Chatbot Arena: An Open Platform for Evaluating <span class="hljs-keyword">LLMs </span><span class="hljs-keyword">by </span>Human <span class="hljs-keyword">Preference},
</span>    author={Wei-Lin Chiang <span class="hljs-keyword">and </span>Lianmin Zheng <span class="hljs-keyword">and </span>Ying <span class="hljs-keyword">Sheng </span><span class="hljs-keyword">and </span>Anastasios Nikolas Angelopoulos <span class="hljs-keyword">and </span>Tianle Li <span class="hljs-keyword">and </span>Dacheng Li <span class="hljs-keyword">and </span>Hao Zhang <span class="hljs-keyword">and </span><span class="hljs-keyword">Banghua </span>Zhu <span class="hljs-keyword">and </span>Michael <span class="hljs-keyword">Jordan </span><span class="hljs-keyword">and </span><span class="hljs-keyword">Joseph </span>E. Gonzalez <span class="hljs-keyword">and </span>Ion Stoica},
    year={<span class="hljs-number">2024</span>},
    eprint={<span class="hljs-number">2403</span>.<span class="hljs-number">04132</span>},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
</code></pre>
</div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"Does style matter? Disentangling style and substance in Chatbot Arena","author":"Tianle Li*, Anastasios Angelopoulos*, Wei-Lin Chiang*","date":"Aug 29, 2024","previewImg":"/images/blog/style_control/logo.png"},"content":"\nWhy is GPT-4o-mini so good? Why does Claude rank so low, when anecdotal experience suggests otherwise?\n\nWe have answers for you. We controlled for the effect of length and markdown, and indeed, *the ranking changed*. This is just a first step towards our larger goal of disentangling **substance** and **style** in Chatbot Arena leaderboard.\n\n**Check out the results below!** Style indeed has a strong effect on models’ performance in the leaderboard. This makes sense—from the perspective of human preference, it’s not just what you say, but how you say it. But now, we have a way of _separating_ the effect of writing style from the content, so you can see both effects individually.\n\nWhen controlling for length and style, we found noticeable shifts in the ranking. GPT-4o-mini and Grok-2-mini drop below most frontier models, and Claude 3.5 Sonnet, Opus, and Llama-3.1-405B rise substantially. In the Hard Prompt subset, Claude 3.5 Sonnet ties for #1 with chatgpt-4o-latest and Llama-3.1-405B climbs to #3. We are looking forward to seeing what the community does with this new tool for disaggregating style and substance!\n\n\n### Overall Ranking + Style Control\n\u003cimg src=\"/images/blog/style_control/comparison_overall.png\" style=\"display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 80%\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003eFigure 1. Overall Chatbot Arena ranking vs Overall Chatbot Arena ranking where answer length, markdown header count, markdown bold count, and markdown list element count are being “controlled”.\u003c/p\u003e\n\n### Hard Prompt Ranking + Style Control\n\u003cimg src=\"/images/blog/style_control/comparison_hard.png\" style=\"display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 80%\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003eFigure 2. Hard Prompt category ranking vs Hard Prompt category ranking where answer length, markdown header count, markdown bold count, and markdown list element count are being “controlled”.\u003c/p\u003e\n\n### Full Leaderboard with Style Control\n\n\u003cimg src=\"/images/blog/style_control/arena_leaderboard.png\" style=\"display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 90%\"\u003e\u003c/img\u003e\n\nPlease find the below links to leaderboard and colab notebook. We will be rolling out style control soon to all the categories. Stay tuned!\n- Leaderboard [link](https://lmarena.ai/?leaderboard)\n- Colab [link](https://colab.research.google.com/drive/19VPOril2FjCX34lJoo7qn4r6adgKLioY#scrollTo=C4xnVybEy0OO)\n\n\n## Methodology\n\n**High-Level Idea.** The goal here is to understand the effect of _style_ vs _substance_ on the Arena Score. Consider models A and B. Model A is great at producing code, factual and unbiased answers, etc., but it outputs short and terse responses. Model B is not so great on substance (e.g., correctness), but it outputs great markdown, and gives long, detailed, flowery responses. Which is better, model A, or model B?\n\nThe answer is not one dimensional. Model A is better on substance, and Model B is better on style. Ideally, we would have a way of teasing apart this distinction: capturing how much of the model’s Arena Score is due to substance or style. \n\nOur methodology is a first step towards this goal. We explicitly model style as an independent variable in our Bradley-Terry regression. For example, we added length as a feature—just like each model, the length difference has its _own_ Arena Score! By doing this, we expect that the Arena Score of each model will reflect its strength, controlled for the effect of length. \n\nPlease read below for the technical details. We also controlled not just for length, but also a few other style features. As a first version, we propose controlling\n1. Answer token length\n2. Number of markdown headers\n3. Number of markdown bold elements\n4. Number of markdown lists\n\nWe publicly release our data with vote and style elements and code on [google colab](https://colab.research.google.com/drive/19VPOril2FjCX34lJoo7qn4r6adgKLioY#scrollTo=dYANZPG_8a9N)! You can try out experimenting with style control now. More improvements to come, and please reach out if you want to help contribute! \n\n**Background.** To produce the results above, we controlled for the effect of style by adding extra “style features” into our Bradley-Terry regression. This is a [standard technique](https://en.wikipedia.org/wiki/Controlling_for_a_variable) in statistics, and has been recently used in LLM evaluations [1]. Additionally, there are studies suggesting potential bias for “pretty” and more detailed responses in humans [2, 3]. The idea is that, by including any confounding variables (e.g. response length) in the regression, we can attribute any increase in strength to the confounder, as opposed to the model. Then, the Bradley-Terry coefficient will be more reflective of the model’s intrinsic ability, as opposed to possible confounders. The definition of a confounder is to some extent up to our interpretation; as our style features, we use the (normalized) difference in response lengths, the number of markdown headers, and the number of lists.\n\nMore formally, consider vectors $X_1, \\ldots, X_n \\in \\mathbb{R}^M$ and $Y_1, \\ldots, Y_n \\in \\{0,1\\}$, where $n$ is the number of battles and $M$ is the number of models. \n\nFor every $i \\in [n]$, We have that $X_{i,m}=1$ only if model $m \\in [M]$ is the model shown in the left-hand side in Chatbot Arena, and $X_{i,m}=-1$ only if it is shown on the right. That is, $X_i$ is a vector with two nonzero elements. The outcome $Y_i$ takes the value $Y_i=1$ if the left-hand model wins, and $Y_i=0$ otherwise. \n\nThe standard method for computing the Arena Score (i.e., the Bradley-Terry coefficients, which we formerly called the Elo score) is to run a logistic regression of $Y_i$ onto $X_i$. That is, for every model $m$, we associate a scalar $\\hat{\\beta}_m$ that describes its strength, and the vector $\\hat{\\beta}$ is determined by solving the following logistic regression:\n\n$$\\hat{\\beta} = \\arg \\min_{\\beta \\in \\mathbb{R}^M} \\frac{1}{n}\\sum\\limits_{i=1}^n \\mathsf{BCELoss}(\\mathsf{sigmoid}(X_i^\\top \\beta), Y_i)$$\n\nwhere  $\\mathsf{BCELoss}$ represents the binary cross-entropy loss. (In practice, we also reweight this objective to handle non-uniform model sampling, but let’s ignore that for now.)\n\n## Style Control\n\nNow, for every battle $i \\in [n]$, let’s say that in addition to $X_i$ that we observe some additional style features, $Z_i \\in \\mathbb{R}^S$. These style features can be as simple or complicated as you want. For example, $Z_i$ could just be the difference in response lengths of the two models, in which case $S=1$. Or, we could have $S\u003e1$ and include other style-related features, for example, the number of markdown headers, common words associated with refusal, or even style features that are automatically extracted by a model!\n\nHere, we define each style feature as\n$$\\text{normalize }\\left(\\frac{\\text{feature}_A - \\text{feature}_B}{\\text{feature}_A + \\text{feature}_B}\\right)$$\n\nFor example, the first new feature, token length difference between answer A and answer B, would be expressed as \n$$\\text{normalize }\\left(\\frac{\\text{length}_A - \\text{length}_B}{\\text{length}_A + \\text{length}_B}\\right)$$\n\nWe divide the difference by the sum of both answers' token length to make the length difference proportional to the pairwise answer token lengths. An answer with 500 tokens is roughly equal in length to an answer with 520 tokens, while an answer with 20 tokens is very different from an answer with 40 tokens, even though the difference is 20 tokens for both scenarios. Alternatively, AlpacaEval LC uses the following normalization technique. \n\n$$\\tanh\\left(\\frac{\\text{feature}_A - \\text{feature}_B)}{\\sigma(\\text{feature}_A - \\text{feature}_B)}\\right)$$.\n \n\nThe idea of style control is very basic. We perform the same logistic regression as before, but with some extra, additive style coefficients:\n$$\\hat{\\beta}, \\hat{\\gamma} = \\arg \\min_{\\beta \\in \\mathbb{R}^M, \\gamma \\in \\mathbb{R}^S} \\frac{1}{n}\\sum\\limits_{i=1}^n \\mathsf{BCELoss}(\\mathsf{sigmoid}(X_i^\\top \\beta + Z_i^{\\top}\\gamma), Y_i).$$\nWe refer to the results $\\hat{\\beta}$ and $\\hat{\\gamma}$ as the “model coefficients” and the “style coefficients” respectively. The model coefficients have the same interpretation as before; however, they are controlled for the effect of style, which is explicitly modeled by the style coefficients!\n\nWhen the style coefficients are big, that means that the style feature has a big effect on the response. To define “big”, you need to properly normalize the style coefficients so they can be compared. All in all, when analyzing the style coefficients, we found that length was the dominant style factor. All other markdown effects are second order.\n\nWe report the following coefficient for each style attribute across different methods of controlling the style.\n\u003ctable style=\"border-collapse: collapse; width: 100%;\"\u003e\n  \u003ctr\u003e\n    \u003cth style=\"text-align: center; padding: 8px;\"\u003e\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px;\"\u003eLength\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px;\"\u003eMarkdown List\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px;\"\u003eMarkdown Header\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px;\"\u003eMarkdown Bold\u003c/th\u003e\n  \u003c/tr\u003e\n\u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003eControl Both\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e0.249\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e0.031\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e0.024\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e0.019\u003c/td\u003e\n  \u003c/tr\u003e\n\u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003eControl Markdown Only\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e-\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e0.111\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e0.044\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e0.056\u003c/td\u003e\n  \u003c/tr\u003e\n\u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003eControl Length Only\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e0.267\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e-\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e-\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e-\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n## Ablation\n\nNext, we compare the ranking changes between controlling for answer length only, markdown element only, and both. We present the Chatbot Arena Overall table first.\n\u003ctable style=\"border-collapse: collapse; width: 100%;\"\u003e\n  \u003ctr\u003e\n    \u003cth style=\"text-align: left; padding: 8px; width: 30%;\"\u003eModel\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px; width: 25%;\"\u003eRank Diff (Length Only)\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px; width: 25%;\"\u003eRank Diff (Markdown Only)\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px; width: 20%;\"\u003eRank Diff (Both)\u003c/th\u003e\n  \u003c/tr\u003e\n\u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003echatgpt-4o-latest\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e1-\u003e1\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e1-\u003e1\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e1-\u003e1\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-pro-exp-0827\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-pro-exp-0801\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4o-2024-05-13\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e5-\u003e3\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e5-\u003e3\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e5-\u003e2\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003eclaude-3-5-sonnet-20240620\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e6-\u003e5\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e6-\u003e4\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e6-\u003e4\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-advanced-0514\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e7-\u003e5\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e7-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e7-\u003e6\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egrok-2-2024-08-13\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e4\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e4\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e5\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003ellama-3.1-405b-instruct\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e6-\u003e6\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e6-\u003e4\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e6-\u003e6\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4o-2024-08-06\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e7-\u003e6\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e7-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e7-\u003e6\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4-turbo-2024-04-09\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e9\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003eclaude-3-opus-20240229\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e14\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e10\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-pro-api-0514\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e10-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e10-\u003e13\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e10-\u003e10\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-flash-exp-0827\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e9\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e9\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4-1106-preview\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e14\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e11\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003e\u003cstrong\u003egpt-4o-mini-2024-07-18\u003c/strong\u003e\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e11\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e11\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4-0125-preview\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e17-\u003e14\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e17-\u003e12\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e17-\u003e13\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003emistral-large-2407\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e14\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e13\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e13\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003eathene-70b-0725\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e16-\u003e16\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e16-\u003e17\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e16-\u003e17\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003e\u003cstrong\u003egrok-2-mini-2024-08-13\u003c/strong\u003e\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e15\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e15\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e6-\u003e18\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-pro-api-0409-preview\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e11-\u003e16\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e11-\u003e21\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e11-\u003e18\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\nWe also perform the same comparison on Chatbot Arena Hard Prompt Category.\n\u003ctable style=\"border-collapse: collapse; width: 100%;\"\u003e\n  \u003ctr\u003e\n    \u003cth style=\"text-align: left; padding: 8px; width: 30%;\"\u003eModel\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px; width: 25%;\"\u003eRank Diff (Length Only)\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px; width: 25%;\"\u003eRank Diff (Markdown Only)\u003c/th\u003e\n    \u003cth style=\"text-align: center; padding: 8px; width: 20%;\"\u003eRank Diff (Both)\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003echatgpt-4o-latest\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e1-\u003e1\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e1-\u003e1\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e1-\u003e1\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003e\u003cstrong\u003eclaude-3-5-sonnet-20240620\u003c/strong\u003e\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e2-\u003e1\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e2-\u003e1\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-pro-exp-0827\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e2-\u003e1\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-pro-exp-0801\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e3\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e3\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e3\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4o-2024-05-13\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e2-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e3\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003ellama-3.1-405b-instruct\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e4-\u003e4\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e4-\u003e2\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e4-\u003e3\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egrok-2-2024-08-13\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e3\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e3\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e2-\u003e4\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-flash-exp-0827\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e4-\u003e4\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e4-\u003e6\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e4-\u003e4\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-1.5-pro-api-0514\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e7-\u003e6\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e7-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e7-\u003e7\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4o-2024-08-06\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e4-\u003e4\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e4-\u003e6\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e4-\u003e4\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egemini-advanced-0514\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e9-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e9-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e9-\u003e7\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003eclaude-3-opus-20240229\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e14-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e14-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e14-\u003e7\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003emistral-large-2407\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e7-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e7-\u003e6\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px;\"\u003e7-\u003e7\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4-1106-preview\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e10\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e7\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4-turbo-2024-04-09\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e9-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e9-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e9-\u003e7\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003eathene-70b-0725\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e11-\u003e7\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4o-mini-2024-07-18\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e4-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e4-\u003e7\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e4-\u003e11\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egpt-4-0125-preview\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e15-\u003e14\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e15-\u003e10\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e15-\u003e13\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003egrok-2-mini-2024-08-13\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e5-\u003e12\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e5-\u003e8\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: red;\"\u003e5-\u003e13\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"text-align: left; padding: 8px;\"\u003edeepseek-coder-v2-0724\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e14\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e13\u003c/td\u003e\n    \u003ctd style=\"text-align: center; padding: 8px; color: green;\"\u003e16-\u003e14\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n\n## Limitations and Future Work \n\nWe want to continue building a pipeline to disentangle style and substance in the arena. Although controlling for style is a big step forward, our analysis is still _observational_. There are possible unobserved confounders such as positive correlation between length and substantive quality that are _not_ accounted for by our study. For example, well-known example of a possible unobserved confounder that might positively impact both length and quality is a chain-of-thought explanation for a reasoning question.\n\nTo address these limitations, we are looking forward to implementing _causal inference_ in our pipeline, and running prospective randomized trials to assess the effect of length, markdown, and more. Our pipeline for style control will be changing as we continue to improve our system and refine the analysis. Stay tuned, and let us know if you want to help!\n\n\n## Reference\n\n[1] Dubois et al. “Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators”, arXiv preprint\n\n[2] Chen et al. “Humans or LLMs as the Judge? A Study on Judgement Bias”, arXiv preprint\n\n[3] Park et al. “Disentangling Length from Quality in Direct Preference Optimization”, arXiv preprint\n\n\n## Citation\n```\n@misc{chiang2024chatbot,\n    title={Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference},\n    author={Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E. Gonzalez and Ion Stoica},\n    year={2024},\n    eprint={2403.04132},\n    archivePrefix={arXiv},\n    primaryClass={cs.AI}\n}\n```\n","slug":"2024-08-28-style-control"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"2024-08-28-style-control"},"buildId":"syzLuWNJ0e7YclZ1XB3I3","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>