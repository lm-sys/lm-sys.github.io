<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/styles/atom-one-light.min.css"/><title>SGLang-Diffusion: Two Months In | LMSYS Org</title><meta name="title" content="SGLang-Diffusion: Two Months In | LMSYS Org"/><meta property="og:title" content="SGLang-Diffusion: Two Months In | LMSYS Org"/><meta name="twitter:title" content="SGLang-Diffusion: Two Months In | LMSYS Org"/><meta name="description" content="&lt;p&gt;Since its release in early Nov. 2025, &lt;strong&gt;SGLang-Diffusion&lt;/strong&gt; has gained significant attention and widespread adoption
within the community. We ..."/><meta property="og:description" content="&lt;p&gt;Since its release in early Nov. 2025, &lt;strong&gt;SGLang-Diffusion&lt;/strong&gt; has gained significant attention and widespread adoption
within the community. We ..."/><meta name="twitter:description" content="&lt;p&gt;Since its release in early Nov. 2025, &lt;strong&gt;SGLang-Diffusion&lt;/strong&gt; has gained significant attention and widespread adoption
within the community. We ..."/><meta property="og:image" content="https://lmsys.org/images/blog/sgl-diffusion/sgl-diffusion-banner-16-9.png"/><meta name="twitter:image" content="https://lmsys.org/images/blog/sgl-diffusion/sgl-diffusion-banner-16-9.png"/><meta name="twitter:image:alt" content="The text: LLMSYS Org, Large Model Systems Organization."/><meta property="og:type" content="website"/><meta property="og:url" content="https://lmsys.org/blog/2026-01-16-sglang-diffusion"/><meta name="twitter:url" content="https://lmsys.org/blog/2026-01-16-sglang-diffusion"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1d1d1f"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.jpeg"/><link rel="icon" href="/favicon.jpeg" type="image/jpg"/><meta name="next-head-count" content="20"/><script src="/mathjax.js" defer=""></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js" defer=""></script><link rel="preload" href="/_next/static/css/664049df48ded145.css" as="style"/><link rel="stylesheet" href="/_next/static/css/664049df48ded145.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-d62cc293bc63f5ee.js" defer=""></script><script src="/_next/static/chunks/286-48ebbaba72d91976.js" defer=""></script><script src="/_next/static/chunks/807-a4eae1dfa8bfbe9f.js" defer=""></script><script src="/_next/static/chunks/138-efd6d72a198878c6.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-c9fe776063d24120.js" defer=""></script><script src="/_next/static/Y1GA5BwdqDtZD1hHEjqCC/_buildManifest.js" defer=""></script><script src="/_next/static/Y1GA5BwdqDtZD1hHEjqCC/_ssgManifest.js" defer=""></script><script src="/_next/static/Y1GA5BwdqDtZD1hHEjqCC/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-sky md:text-paper md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LMSYS ORG</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/blog/">Blog</a><a href="/about/">About</a><a href="/donations/">Donations</a><a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">Chatbot Arena (graduated)</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://slack.sglang.io" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1d1d1f;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/blog/">Blog</a></p><p><a href="/about/">About</a></p><p><a href="/donations/">Donations</a></p><p><a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">Chatbot Arena (graduated)</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.gg/HSWAKCrnFx" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-sky grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5" lang="en"><h1 lang="en" style="hyphens:auto" class="text-4xl md:text-4xl w-full font-bold break-words">SGLang-Diffusion: Two Months In</h1><p class="text-xl pt-2 pb-2">by: <!-- -->The SGLang-Diffusion Team<!-- -->,<!-- --> <!-- -->Jan 16, 2026<!-- --></p><hr/><div class="pt-2 article"><p>Since its release in early Nov. 2025, <strong>SGLang-Diffusion</strong> has gained significant attention and widespread adoption
within the community. We are deeply grateful for the extensive feedback and growing number of contributions from
open-source developers.</p>
<p>Over the past two months, we've been meticulously optimizing SGLang-Diffusion, now (docker image tag: <code>lmsysorg/sglang:dev-pr-17247</code>) up to 2.5x faster than our initial release.</p>
<p>Here is a summary of our progress:</p>
<h2><a id="overview" class="anchor" href="#overview" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overview</h2>
<p><strong>New Models</strong>:</p>
<ul>
<li>Day-0 support for Flux.2, Qwen-Image-Edit-2511, Qwen-Image-2512, Z-Image-Turbo, Qwen-Image-Layered, TurboWan,
GLM-Image and more.</li>
<li>Run SGLang-Diffusion with diffusers backend: compatible with all models in diffusers; more improvements are planned (see <a href="https://github.com/sgl-project/sglang/issues/16642">Issue #16642</a>).</li>
</ul>
<p><strong>LoRA Support</strong>:</p>
<ul>
<li>We support almost all LoRA formats for supported models. This section lists some example LoRAs that have been
explicitly tested and verified.
<table>
<thead>
<tr>
<th>Base Model</th>
<th>Supported LoRAs</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Wan2.2</strong></td>
<td><code>lightx2v/Wan2.2-Distill-Loras</code><br> <code>Cseti/wan2.2-14B-Arcane_Jinx-lora-v1</code></td>
</tr>
<tr>
<td><strong>Wan2.1</strong></td>
<td><code>lightx2v/Wan2.1-Distill-Loras</code></td>
</tr>
<tr>
<td><strong>Z-Image-Turbo</strong></td>
<td><code>tarn59/pixel_art_style_lora_z_image_turbo</code><br> <code>wcde/Z-Image-Turbo-DeJPEG-Lora</code></td>
</tr>
<tr>
<td><strong>Qwen-Image</strong></td>
<td><code>lightx2v/Qwen-Image-Lightning</code><br> <code>flymy-ai/qwen-image-realism-lora</code><br> <code>prithivMLmods/Qwen-Image-HeadshotX</code><br> <code>starsfriday/Qwen-Image-EVA-LoRA</code></td>
</tr>
<tr>
<td><strong>Qwen-Image-Edit</strong></td>
<td><code>ostris/qwen_image_edit_inpainting</code><br> <code>lightx2v/Qwen-Image-Edit-2511-Lightning</code></td>
</tr>
<tr>
<td><strong>Flux</strong></td>
<td><code>dvyio/flux-lora-simple-illustration</code><br> <code>XLabs-AI/flux-furry-lora</code><br> <code>XLabs-AI/flux-RealismLora</code></td>
</tr>
</tbody>
</table>
</li>
<li>Fully functional HTTP API:
<table>
<thead>
<tr>
<th>Feature</th>
<th>API Endpoint</th>
<th>Key Parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td>Set or Activate (multiple) LoRA(s)</td>
<td><code>/v1/set_lora</code></td>
<td><code>lora_nickname</code>, <code>lora_path</code>, <code>strength</code>, <code>target</code></td>
</tr>
<tr>
<td>Merge Weights</td>
<td><code>/v1/merge_lora_weights</code></td>
<td><code>strength</code>, <code>target</code></td>
</tr>
<tr>
<td>Unmerge Weights</td>
<td><code>/v1/unmerge_lora_weights</code></td>
<td>-</td>
</tr>
<tr>
<td>List Adapters</td>
<td><code>/v1/list_loras</code></td>
<td>-</td>
</tr>
</tbody>
</table>
</li>
</ul>
<p><strong>Parallelism</strong>: Support SP and TP for most models, alongside hybrid parallelism (combinations of Ulysses
Parallel, Ring Parallel, and Tensor Parallel).</p>
<p><strong>Attention Backend</strong>: SageAttention2, SageAttention3 and SLA, more backends are planned.</p>
<p><strong>Hardware Support</strong>: AMD, 4090, 5090, MUSA</p>
<p><strong>SGLang-Diffusion x ComfyUI Integration</strong>: We have implemented a flexible ComfyUI custom node that integrates SGLang-Diffusion's high-performance inference engine. See <a href="https://github.com/sgl-project/sglang/blob/76f69b77530c734ff9b92b5d036316ba097ba943/python/sglang/multimodal_gen/apps/ComfyUI_SGLDiffusion/README.md">usage guide</a>.</p>
<p>While ComfyUI offers exceptional flexibility via custom nodes, it often
lacks multi-GPU support and optimal performance.</p>
<p>Our solution replaces ComfyUI's denoising model forward pass with
SGLang's optimized implementation, preserving ComfyUI's flexibility while leveraging SGLang's superior inference. Users
can simply swap ComfyUI's loader with our SGL-Diffusion UNET Loader to enable enhanced performance without
modifying existing workflows.</p>
<p><img src="/images/blog/sgl-diffusion-26-01/comfyui.png" style="display:block; width: 220%; margin:15px auto 0 auto"></img></p>
<p style="color:gray; text-align: center;">SGLang-Diffusion Plugin in ComfyUI</p>
<h2><a id="performance-benchmark" class="anchor" href="#performance-benchmark" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Performance Benchmark</h2>
<p>Here are some performance benchmark results:</p>
<ul>
<li>We benchmarked SGLang-Diffusion (docker image tag: <code>lmsysorg/sglang:dev-pr-17247</code>) across popular models, comparing it against previous version (Nov. 2025) and other frameworks. SGLang-Diffusion achieves state-of-the-art speeds on NVIDIA GPUs, outperforming all other solutions by up to 5x.</li>
</ul>
<iframe style="display:block; margin: auto;" width="969" height="923" seamless frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQRK_j_q8NXZKEqtrTBagxFxvvaxYXXB56HTqqYlD_aAv1v74WKle2HIc7HPK3P0ZVrYlZrjshKYnaV/pubchart?oid=1681696401&amp;format=interactive"></iframe>
<ul>
<li>We compared the performance of SGLang-Diffusion under different environments with one of the fastest vendors.</li>
</ul>
<iframe style="display:block; margin: auto;" width="969" height="780" seamless frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQRK_j_q8NXZKEqtrTBagxFxvvaxYXXB56HTqqYlD_aAv1v74WKle2HIc7HPK3P0ZVrYlZrjshKYnaV/pubchart?oid=174425525&amp;format=interactive"></iframe>
<ul>
<li>We also evaluated SGLang-Diffusion on AMD GPU:</li>
</ul>
<iframe style="display:block; margin: auto;" width="852" height="321" seamless frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQCc9ulnNOE8mpM2RjIgZLJlLKxK_KUyws3WlTB1mVz2Ywx790G0IVbrI7-gjY_O5D8G5Grcjb1dBkR/pubchart?oid=319708956&amp;format=interactive"></iframe>
<h2><a id="key-improvements" class="anchor" href="#key-improvements" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Key Improvements</h2>
<p>To serve as a robust, industrial-grade framework, <strong>speed, stability, and code quality</strong> are our top priorities. We have
refactored key components to eliminate bottlenecks and maximize hardware efficiency.</p>
<p>Here are the highlights of our recent technical improvements:</p>
<h3><a id="1-layerwise-offload" class="anchor" href="#1-layerwise-offload" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1. Layerwise Offload</h3>
<p>From our early profiling, we identified model loading/offloading as a major bottleneck, since the compute stream has to
wait until all the weights are on-device, and most GPUs are not equipped with sufficient VRAM to keep all components in
memory throughout inference.</p>
<p>To tackle this, we introduced:</p>
<ol>
<li><code>LayerwiseOffloadManager</code>: A manager class that provides hooks for <strong>prefetching</strong> weights of the next layer while
computing on the current layer, as well as <strong>releasing</strong> hooks after compute.</li>
<li><code>OffloadableDiTMixin</code>: A mixin class that registers <code>LayerwiseOffloadManager</code>'s prefetch and release hooks for the
diffusion-transformer.</li>
</ol>
<p>which has the following benefits:</p>
<ul>
<li><strong>Compute-Loading Overlap</strong>: Overlapping computation with weight loading eliminates stalls on the copy stream,
significantly boosting inference speed â€” especially for multi-DiT architectures like Wan2.2</li>
<li><strong>VRAM Optimization</strong>: A reduced peak VRAM footprint enables the generation of longer video sequences and
higher-resolution content</li>
</ul>
<p><img src="/images/blog/sgl-diffusion-26-01/layerwise offload vs serial.png" style="display:block; margin: auto; width: 100%;"></img></p>
<p style="color:gray; text-align: center;">Comparison of Standard Loading with Layerwise Offload</p>
<p><strong>Layerwise Offload</strong> is now enabled for video models by default.</p>
<p>See related
PRs (<a href="https://github.com/sgl-project/sglang/pull/15511">#15511</a>, <a href="https://github.com/sgl-project/sglang/pull/16150">#16150</a>).</p>
<h3><a id="2-kernel-improvements" class="anchor" href="#2-kernel-improvements" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2. Kernel Improvements</h3>
<ul>
<li><strong>Upstream FlashAttention</strong>: We synchronized our kernels with the latest upstream version from Dao-AILab to eliminate performance lags. See <a href="https://github.com/sgl-project/sglang/pull/16382">#16382</a>.</li>
<li><strong>Optimized QKV Processing</strong>: We analyzed the performance trade-offs between Packed QKV and downstream kernels (e.g., <code>qk_norm</code>, FlashInfer RoPE). To achieve optimal preprocessing performance, we implemented QKV unpacking without introducing extra contiguous memory operations.</li>
<li><strong>JIT QK Norm Kernel</strong>: Fused Q/K RMSNorm into a single inplace kernel to cut launch count and memory traffic before
attention.</li>
<li><strong>FlashInfer RoPE</strong>: Apply RoPE on Q/K inplace with FlashInfer when available (fallback otherwise), reducing RoPE
overhead and intermediate tensor materialization.</li>
<li><strong>Weight Fusion (Operator Fusion)</strong>: Fused projection + activation patterns (e.g., gate/up merge + SiLU&amp;Mul) to reduce
GEMM count and elementwise launches in DiT blocks.</li>
<li><strong>Timestep Implementation</strong>: Use a dedicated CUDA kernel for timestep sinusoidal embedding (sin/cos) to reduce
per-step overhead in diffusion scheduling. See <a href="https://github.com/sgl-project/sglang/pull/12995">#12995</a>.</li>
</ul>
<h3><a id="3-cache-dit-integration" class="anchor" href="#3-cache-dit-integration" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3. Cache-DiT Integration</h3>
<p>We've integrated <a href="https://github.com/vipshop/cache-dit">Cache-DiTðŸ¤—</a>, the most popular framework for DiT cache,
seamlessly into SGLang-Diffusion, fully compatible with <code>torch.compile</code>, Ulysses Parallel, Ring Parallel, and Tensor
Parallel, along with any hybrid combination of these three.
See <a href="https://github.com/sgl-project/sglang/pull/14234">#14234</a>, <a href="https://github.com/sgl-project/sglang/pull/15163">#15163</a> and <a href="https://github.com/sgl-project/sglang/pull/16532">#16532</a>
for implementation details.</p>
<p>By setting just a few environment variables, generation speed can increase by up to 169%.</p>
<p>Here is an example to enable Cache-DiT in SGLang-Diffusion:</p>
<pre><code class="hljs language-bash">SGLANG_CACHE_DIT_ENABLED=<span class="hljs-literal">true</span> \
SGLANG_CACHE_DIT_SCM_PRESET=fast \
sglang generate --model-path=Qwen/Qwen-Image --prompt=<span class="hljs-string">&quot;Cinematic establishing shot of a city at dusk&quot;</span>
  --save-output
</code></pre>
<p>Furthermore, we can now integrate and refine Cache-DiT optimizations to our newly-supported diffuser backend (see <a href="https://github.com/sgl-project/sglang/issues/16642">Issue #16642</a>).</p>
<h3><a id="4-few-more-things" class="anchor" href="#4-few-more-things" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4. Few More Things</h3>
<ul>
<li><strong>Memory Monitoring</strong>: Peak usage statistics available across offline generation and online serving workflows.</li>
<li><a href="https://github.com/sgl-project/sglang/blob/main/python/sglang/multimodal_gen/docs/profiling.md"><strong>Profiling Suite</strong></a>:
Full-stage support with step-by-step docs for PyTorch Profiler and Nsight Systems.</li>
<li><a href="https://cookbook.sglang.io/docs/diffusion/"><strong>Diffusion Cookbook</strong></a>: Curated recipes, best practices, and
benchmarking guides for SGLang-Diffusion.</li>
</ul>
<h2><a id="roadmap" class="anchor" href="#roadmap" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Roadmap</h2>
<ul>
<li>Sparse Attention Backends</li>
<li>Quantization (nunchaku, nvfp4 and others)</li>
<li>Optimizations on consumer-level GPUs</li>
<li>Codesign with <a href="https://github.com/sgl-project/sglang/issues/16546">sglang-omni</a></li>
</ul>
<h2><a id="acknowledgment" class="anchor" href="#acknowledgment" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Acknowledgment</h2>
<p><strong>SGLang-Diffusion Team</strong>:</p>
<p>Aichen Feng, Adarsh Shirawalmath, Alison Shao, Changyi Yang, Chunan Zeng, DefTruth, Fan Lin, Fan Luo, Fenglin Yu, Gaoji Liu, Heyang Huang, Hongli Mi,
Huanhuan Chen, Ji Huang, Jiajun Li, Ji Li, Jinliang Li, Junlin Lv, Jianying Zhu, Jiaqi Zhu, Mingfa Feng, Ran Mei, Ruiguo Yang, Shenggui Li,
Shuyi Fan, Shuxi Guo, Triple Mu, Wang Xingyu, Weitao Dai, Wenhao Zhang, Xi Chen, Xiao Jin, Xiaoyu Zhang (BBuf), Yihan Chen, Yikai Zhu, Yin Fan, Yuhao
Yang, Yixuan Zhang, Yuan Luo, Yueming Yuan, Yuhang Qi, Yuzhen Zhou, Zhiyi Liu, Zhuorui Liu, Ziyi Xu, Mick</p>
<p>Special thanks to NVIDIA and Voltage Park for their compute support.</p>
<p>Special thanks to AMD for their compute support and assistance in development.</p>
<h2><a id="learn-more" class="anchor" href="#learn-more" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Learn more</h2>
<ul>
<li><strong>Slack channel</strong>: <a href="https://sgl-fru7574.slack.com/archives/C09P0HTKE6A">#diffusion</a> (join via slack.sglang.io)</li>
<li><a href="https://cookbook.sglang.io/docs/diffusion"><strong>Cookbook for SGLang-Diffusion</strong></a></li>
<li><a href="https://github.com/sgl-project/sglang/blob/main/python/sglang/multimodal_gen/docs"><strong>Documentation on SGLang-Diffusion</strong></a></li>
</ul>
</div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"SGLang-Diffusion: Two Months In","author":"The SGLang-Diffusion Team","date":"January 16, 2026","previewImg":"/images/blog/sgl-diffusion/sgl-diffusion-banner-16-9.png"},"content":"\nSince its release in early Nov. 2025, **SGLang-Diffusion** has gained significant attention and widespread adoption\nwithin the community. We are deeply grateful for the extensive feedback and growing number of contributions from\nopen-source developers.\n\nOver the past two months, we've been meticulously optimizing SGLang-Diffusion, now (docker image tag: `lmsysorg/sglang:dev-pr-17247`) up to 2.5x faster than our initial release.\n\nHere is a summary of our progress:\n\n## Overview\n\n**New Models**:\n\n- Day-0 support for Flux.2, Qwen-Image-Edit-2511, Qwen-Image-2512, Z-Image-Turbo, Qwen-Image-Layered, TurboWan,\n  GLM-Image and more.\n- Run SGLang-Diffusion with diffusers backend: compatible with all models in diffusers; more improvements are planned (see [Issue #16642](https://github.com/sgl-project/sglang/issues/16642)).\n\n**LoRA Support**:\n\n- We support almost all LoRA formats for supported models. This section lists some example LoRAs that have been\n  explicitly tested and verified.\n  | Base Model | Supported LoRAs |\n  |-------------------|------------------|\n  | **Wan2.2**        | `lightx2v/Wan2.2-Distill-Loras`\u003cbr\u003e `Cseti/wan2.2-14B-Arcane_Jinx-lora-v1` |\n  | **Wan2.1**        | `lightx2v/Wan2.1-Distill-Loras` |\n  | **Z-Image-Turbo** | `tarn59/pixel_art_style_lora_z_image_turbo`\u003cbr\u003e `wcde/Z-Image-Turbo-DeJPEG-Lora` |\n  | **Qwen-Image**    | `lightx2v/Qwen-Image-Lightning`\u003cbr\u003e `flymy-ai/qwen-image-realism-lora`\u003cbr\u003e `prithivMLmods/Qwen-Image-HeadshotX`\u003cbr\u003e `starsfriday/Qwen-Image-EVA-LoRA` |\n  | **Qwen-Image-Edit** | `ostris/qwen_image_edit_inpainting`\u003cbr\u003e `lightx2v/Qwen-Image-Edit-2511-Lightning` |\n  | **Flux**          | `dvyio/flux-lora-simple-illustration`\u003cbr\u003e `XLabs-AI/flux-furry-lora`\u003cbr\u003e `XLabs-AI/flux-RealismLora` |\n- Fully functional HTTP API:\n  | Feature | API Endpoint | Key Parameters |\n  |---------------------------------|-----------------------------|--------------------------------------------------|\n  | Set or Activate (multiple) LoRA(s) | `/v1/set_lora`              | `lora_nickname`, `lora_path`, `strength`, `target` |\n  | Merge Weights | `/v1/merge_lora_weights`    | `strength`, `target`                             |\n  | Unmerge Weights | `/v1/unmerge_lora_weights`  | - |\n  | List Adapters | `/v1/list_loras`            | - |\n\n**Parallelism**: Support SP and TP for most models, alongside hybrid parallelism (combinations of Ulysses\nParallel, Ring Parallel, and Tensor Parallel).\n\n**Attention Backend**: SageAttention2, SageAttention3 and SLA, more backends are planned.\n\n**Hardware Support**: AMD, 4090, 5090, MUSA\n\n**SGLang-Diffusion x ComfyUI Integration**: We have implemented a flexible ComfyUI custom node that integrates SGLang-Diffusion's high-performance inference engine. See [usage guide](https://github.com/sgl-project/sglang/blob/76f69b77530c734ff9b92b5d036316ba097ba943/python/sglang/multimodal_gen/apps/ComfyUI_SGLDiffusion/README.md).\n\nWhile ComfyUI offers exceptional flexibility via custom nodes, it often\nlacks multi-GPU support and optimal performance.\n\nOur solution replaces ComfyUI's denoising model forward pass with\nSGLang's optimized implementation, preserving ComfyUI's flexibility while leveraging SGLang's superior inference. Users\ncan simply swap ComfyUI's loader with our SGL-Diffusion UNET Loader to enable enhanced performance without\nmodifying existing workflows.\n\n\u003cimg src=\"/images/blog/sgl-diffusion-26-01/comfyui.png\" style=\"display:block; width: 220%; margin:15px auto 0 auto\"\u003e\u003c/img\u003e\n\u003cp style=\"color:gray; text-align: center;\"\u003eSGLang-Diffusion Plugin in ComfyUI\u003c/p\u003e\n\n## Performance Benchmark\n\nHere are some performance benchmark results:\n\n- We benchmarked SGLang-Diffusion (docker image tag: `lmsysorg/sglang:dev-pr-17247`) across popular models, comparing it against previous version (Nov. 2025) and other frameworks. SGLang-Diffusion achieves state-of-the-art speeds on NVIDIA GPUs, outperforming all other solutions by up to 5x.\n\n[//]: # (\u003ciframe width=\"984\" height=\"923\" seamless frameborder=\"0\" scrolling=\"no\" src=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQRK_j_q8NXZKEqtrTBagxFxvvaxYXXB56HTqqYlD_aAv1v74WKle2HIc7HPK3P0ZVrYlZrjshKYnaV/pubchart?oid=1022178651\u0026amp;format=interactive\"\u003e\u003c/iframe\u003e)\n\u003ciframe style=\"display:block; margin: auto;\" width=\"969\" height=\"923\" seamless frameborder=\"0\" scrolling=\"no\" src=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQRK_j_q8NXZKEqtrTBagxFxvvaxYXXB56HTqqYlD_aAv1v74WKle2HIc7HPK3P0ZVrYlZrjshKYnaV/pubchart?oid=1681696401\u0026amp;format=interactive\"\u003e\u003c/iframe\u003e\n\n- We compared the performance of SGLang-Diffusion under different environments with one of the fastest vendors.\n\u003ciframe style=\"display:block; margin: auto;\" width=\"969\" height=\"780\" seamless frameborder=\"0\" scrolling=\"no\" src=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQRK_j_q8NXZKEqtrTBagxFxvvaxYXXB56HTqqYlD_aAv1v74WKle2HIc7HPK3P0ZVrYlZrjshKYnaV/pubchart?oid=174425525\u0026amp;format=interactive\"\u003e\u003c/iframe\u003e\n\n\n- We also evaluated SGLang-Diffusion on AMD GPU:\n\u003ciframe style=\"display:block; margin: auto;\" width=\"852\" height=\"321\" seamless frameborder=\"0\" scrolling=\"no\" src=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQCc9ulnNOE8mpM2RjIgZLJlLKxK_KUyws3WlTB1mVz2Ywx790G0IVbrI7-gjY_O5D8G5Grcjb1dBkR/pubchart?oid=319708956\u0026amp;format=interactive\"\u003e\u003c/iframe\u003e\n\n## Key Improvements\n\nTo serve as a robust, industrial-grade framework, **speed, stability, and code quality** are our top priorities. We have\nrefactored key components to eliminate bottlenecks and maximize hardware efficiency.\n\nHere are the highlights of our recent technical improvements:\n\n### 1. Layerwise Offload\n\nFrom our early profiling, we identified model loading/offloading as a major bottleneck, since the compute stream has to\nwait until all the weights are on-device, and most GPUs are not equipped with sufficient VRAM to keep all components in\nmemory throughout inference.\n\nTo tackle this, we introduced:\n\n1. `LayerwiseOffloadManager`: A manager class that provides hooks for **prefetching** weights of the next layer while\n   computing on the current layer, as well as **releasing** hooks after compute.\n2. `OffloadableDiTMixin`: A mixin class that registers `LayerwiseOffloadManager`'s prefetch and release hooks for the\n   diffusion-transformer.\n\nwhich has the following benefits:\n\n- **Compute-Loading Overlap**: Overlapping computation with weight loading eliminates stalls on the copy stream,\n  significantly boosting inference speed â€” especially for multi-DiT architectures like Wan2.2\n- **VRAM Optimization**: A reduced peak VRAM footprint enables the generation of longer video sequences and\n  higher-resolution content\n\n\u003cimg src=\"/images/blog/sgl-diffusion-26-01/layerwise offload vs serial.png\" style=\"display:block; margin: auto; width: 100%;\"\u003e\u003c/img\u003e\n\n\u003cp style=\"color:gray; text-align: center;\"\u003eComparison of Standard Loading with Layerwise Offload\u003c/p\u003e\n\n\n**Layerwise Offload** is now enabled for video models by default.\n\nSee related\nPRs ([#15511](https://github.com/sgl-project/sglang/pull/15511), [#16150](https://github.com/sgl-project/sglang/pull/16150)).\n\n### 2. Kernel Improvements\n\n- **Upstream FlashAttention**: We synchronized our kernels with the latest upstream version from Dao-AILab to eliminate performance lags. See [#16382](https://github.com/sgl-project/sglang/pull/16382).\n- **Optimized QKV Processing**: We analyzed the performance trade-offs between Packed QKV and downstream kernels (e.g., `qk_norm`, FlashInfer RoPE). To achieve optimal preprocessing performance, we implemented QKV unpacking without introducing extra contiguous memory operations.\n- **JIT QK Norm Kernel**: Fused Q/K RMSNorm into a single inplace kernel to cut launch count and memory traffic before\n  attention.\n- **FlashInfer RoPE**: Apply RoPE on Q/K inplace with FlashInfer when available (fallback otherwise), reducing RoPE\n  overhead and intermediate tensor materialization.\n- **Weight Fusion (Operator Fusion)**: Fused projection + activation patterns (e.g., gate/up merge + SiLU\u0026Mul) to reduce\n  GEMM count and elementwise launches in DiT blocks.\n- **Timestep Implementation**: Use a dedicated CUDA kernel for timestep sinusoidal embedding (sin/cos) to reduce\n  per-step overhead in diffusion scheduling. See [#12995](https://github.com/sgl-project/sglang/pull/12995).\n\n\n### 3. Cache-DiT Integration\n\nWe've integrated [Cache-DiTðŸ¤—](https://github.com/vipshop/cache-dit), the most popular framework for DiT cache,\nseamlessly into SGLang-Diffusion, fully compatible with `torch.compile`, Ulysses Parallel, Ring Parallel, and Tensor\nParallel, along with any hybrid combination of these three.\nSee [#14234](https://github.com/sgl-project/sglang/pull/14234), [#15163](https://github.com/sgl-project/sglang/pull/15163) and [#16532](https://github.com/sgl-project/sglang/pull/16532)\nfor implementation details.\n\nBy setting just a few environment variables, generation speed can increase by up to 169%.\n\nHere is an example to enable Cache-DiT in SGLang-Diffusion:\n\n```bash\nSGLANG_CACHE_DIT_ENABLED=true \\\nSGLANG_CACHE_DIT_SCM_PRESET=fast \\\nsglang generate --model-path=Qwen/Qwen-Image --prompt=\"Cinematic establishing shot of a city at dusk\"\n  --save-output\n```\n\nFurthermore, we can now integrate and refine Cache-DiT optimizations to our newly-supported diffuser backend (see [Issue #16642](https://github.com/sgl-project/sglang/issues/16642)).\n\n### 4. Few More Things\n\n- **Memory Monitoring**: Peak usage statistics available across offline generation and online serving workflows.\n- [**Profiling Suite**](https://github.com/sgl-project/sglang/blob/main/python/sglang/multimodal_gen/docs/profiling.md):\n  Full-stage support with step-by-step docs for PyTorch Profiler and Nsight Systems.\n- [**Diffusion Cookbook**](https://cookbook.sglang.io/docs/diffusion/): Curated recipes, best practices, and\n  benchmarking guides for SGLang-Diffusion.\n\n## Roadmap\n\n- Sparse Attention Backends\n- Quantization (nunchaku, nvfp4 and others)\n- Optimizations on consumer-level GPUs\n- Codesign with [sglang-omni](https://github.com/sgl-project/sglang/issues/16546)\n\n## Acknowledgment\n\n**SGLang-Diffusion Team**:\n\nAichen Feng, Adarsh Shirawalmath, Alison Shao, Changyi Yang, Chunan Zeng, DefTruth, Fan Lin, Fan Luo, Fenglin Yu, Gaoji Liu, Heyang Huang, Hongli Mi,\nHuanhuan Chen, Ji Huang, Jiajun Li, Ji Li, Jinliang Li, Junlin Lv, Jianying Zhu, Jiaqi Zhu, Mingfa Feng, Ran Mei, Ruiguo Yang, Shenggui Li,\nShuyi Fan, Shuxi Guo, Triple Mu, Wang Xingyu, Weitao Dai, Wenhao Zhang, Xi Chen, Xiao Jin, Xiaoyu Zhang (BBuf), Yihan Chen, Yikai Zhu, Yin Fan, Yuhao\nYang, Yixuan Zhang, Yuan Luo, Yueming Yuan, Yuhang Qi, Yuzhen Zhou, Zhiyi Liu, Zhuorui Liu, Ziyi Xu, Mick\n\nSpecial thanks to NVIDIA and Voltage Park for their compute support.\n\nSpecial thanks to AMD for their compute support and assistance in development.\n\n## Learn more\n\n- **Slack channel**: [#diffusion](https://sgl-fru7574.slack.com/archives/C09P0HTKE6A) (join via slack.sglang.io)\n- [**Cookbook for SGLang-Diffusion**](https://cookbook.sglang.io/docs/diffusion)\n- [**Documentation on SGLang-Diffusion**](https://github.com/sgl-project/sglang/blob/main/python/sglang/multimodal_gen/docs)\n","slug":"2026-01-16-sglang-diffusion"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"2026-01-16-sglang-diffusion"},"buildId":"Y1GA5BwdqDtZD1hHEjqCC","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>