<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/styles/atom-one-light.min.css"/><title>SpecForge: Accelerating Speculative Decoding Training for SGLang | LMSYS Org</title><meta name="title" content="SpecForge: Accelerating Speculative Decoding Training for SGLang | LMSYS Org"/><meta property="og:title" content="SpecForge: Accelerating Speculative Decoding Training for SGLang | LMSYS Org"/><meta name="twitter:title" content="SpecForge: Accelerating Speculative Decoding Training for SGLang | LMSYS Org"/><meta name="description" content="&lt;p&gt;Speculative decoding is a powerful technique for accelerating Large Language Model (LLM) inference. In this blog post, we are excited to announce the open..."/><meta property="og:description" content="&lt;p&gt;Speculative decoding is a powerful technique for accelerating Large Language Model (LLM) inference. In this blog post, we are excited to announce the open..."/><meta name="twitter:description" content="&lt;p&gt;Speculative decoding is a powerful technique for accelerating Large Language Model (LLM) inference. In this blog post, we are excited to announce the open..."/><meta property="og:image" content="https://lmsys.org/images/blog/spec_forge/logo.jpg"/><meta name="twitter:image" content="https://lmsys.org/images/blog/spec_forge/logo.jpg"/><meta name="twitter:image:alt" content="The text: LLMSYS Org, Large Model Systems Organization."/><meta property="og:type" content="website"/><meta property="og:url" content="https://lmsys.org/blog/2025-07-25-spec-forge"/><meta name="twitter:url" content="https://lmsys.org/blog/2025-07-25-spec-forge"/><meta name="twitter:card" content="summary_large_image"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="theme-color" content="#1d1d1f"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon.jpeg"/><link rel="icon" href="/favicon.jpeg" type="image/jpg"/><meta name="next-head-count" content="20"/><script src="/mathjax.js" defer=""></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js" defer=""></script><link rel="preload" href="/_next/static/css/664049df48ded145.css" as="style"/><link rel="stylesheet" href="/_next/static/css/664049df48ded145.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script src="/_next/static/chunks/framework-a87821de553db91d.js" defer=""></script><script src="/_next/static/chunks/main-6a269cfcb9446759.js" defer=""></script><script src="/_next/static/chunks/pages/_app-0bb93d4b49319e30.js" defer=""></script><script src="/_next/static/chunks/286-48ebbaba72d91976.js" defer=""></script><script src="/_next/static/chunks/807-a4eae1dfa8bfbe9f.js" defer=""></script><script src="/_next/static/chunks/138-efd6d72a198878c6.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-c9fe776063d24120.js" defer=""></script><script src="/_next/static/lPJfP7GoXQIPsGhAR1mjA/_buildManifest.js" defer=""></script><script src="/_next/static/lPJfP7GoXQIPsGhAR1mjA/_ssgManifest.js" defer=""></script><script src="/_next/static/lPJfP7GoXQIPsGhAR1mjA/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="w-screen full-container flex-col md:flex-row flex "><div class="md:basis-1/5 "><div class="navbar fixed w-full flex md:flex-col px-4 md:px-6 py-2 md:py-6 md:pb-7 z-30 bg-sky text-paper md:h-full items-center justify-between md:static md:w-auto md:bg-sky md:text-paper md:max-h-screen md:justify-between child:pl-2 child:md:pl-0 child:text-lg "><div><p class="text-4xl md:text-7xl cursor-pointer font-bold pl-0 md:pb-3">LMSYS ORG</p><div class="md:flex child:pl-3 md:text-xl child:md:pl-1 child:md:pt-2 hidden md:flex-col child:brightness-100 child:transition"><a href="/projects/">Projects</a><a href="/blog/">Blog</a><a href="/about/">About</a><a href="/donations/">Donations</a><a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">Chatbot Arena (graduated)</a></div></div><div class="child:mr-3 -ml-0.5 child:w-8 child:brightness-100 child:transition hidden md:flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://slack.sglang.ai" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div><div class="md:hidden"><div><div class="bm-overlay" style="position:fixed;z-index:1000;width:100%;height:100%;background:rgba(0, 0, 0, 0.3);opacity:0;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:opacity 0.3s, transform 0s 0.3s;top:0px;left:0px"></div><div><div class="bm-burger-button" style="z-index:1000;position:fixed;width:1.2em;height:1.0em;right:1.2rem;top:1em"><button type="button" id="react-burger-menu-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer">Open Menu</button><span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:0%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:40%;opacity:1;background:#fff"></span><span class="bm-burger-bars" style="position:absolute;height:20%;left:0;right:0;top:80%;opacity:1;background:#fff"></span></span></div></div><div id="" class="bm-menu-wrap" style="position:fixed;right:0;z-index:1100;width:300px;height:100%;-moz-transform:translate3d(100%, 0, 0);-ms-transform:translate3d(100%, 0, 0);-o-transform:translate3d(100%, 0, 0);-webkit-transform:translate3d(100%, 0, 0);transform:translate3d(100%, 0, 0);transition:all 0.5s;top:0px" aria-hidden="true"><div class="bm-menu" style="height:100%;box-sizing:border-box;overflow:auto;background:#1d1d1f;padding:2.5em 1.5em 0"><nav class="bm-item-list" style="height:100%;color:#fff;padding:0.8em"><div class="bm-item" style="display:inline-block" tabindex="-1"><div class="child:pb-2 child:child:text-2xl"><p><a href="/projects/">Projects</a></p><p><a href="/blog/">Blog</a></p><p><a href="/about/">About</a></p><p><a href="/donations/">Donations</a></p><p><a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">Chatbot Arena (graduated)</a></p></div><div class="child:mr-3 pt-4 child:w-8 child:brightness-100 hover:child:brightness-90 child:transition flex"><a href="mailto:lmsys.org@gmail.com" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a><a href="https://discord.gg/HSWAKCrnFx" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg></a><a href="https://github.com/lm-sys" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/lmsysorg" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://lmsys.org/rss.xml" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a></div></div></nav></div><div><div class="bm-cross-button" style="position:absolute;width:24px;height:24px;right:8px;top:8px"><button type="button" id="react-burger-cross-btn" style="position:absolute;left:0;top:0;z-index:1;width:100%;height:100%;margin:0;padding:0;border:none;font-size:0;background:transparent;cursor:pointer" tabindex="-1">Close Menu</button><span style="position:absolute;top:6px;right:14px"><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(45deg);background:#fff"></span><span class="bm-cross" style="position:absolute;width:3px;height:14px;transform:rotate(-45deg);background:#fff"></span></span></div></div></div></div></div></div></div><div id="content" class="md:overflow-y-scroll md:max-h-screen md:z-50 md:shadow-lg shadow-neutral-600/70 text-sky grow md:grow-0 md:basis-4/5 flex child:grow flex-col "><div class="" style="opacity:0"><div class="w-full flex justify-center py-5 pt-16 md:pt-5"><div class="container px-5" lang="en"><h1 lang="en" style="hyphens:auto" class="text-4xl md:text-4xl w-full font-bold break-words">SpecForge: Accelerating Speculative Decoding Training for SGLang</h1><p class="text-xl pt-2 pb-2">by: <!-- -->The SGLang Team<!-- -->,<!-- --> <!-- -->Jul 25, 2025<!-- --></p><hr/><div class="pt-2 article"><p>Speculative decoding is a powerful technique for accelerating Large Language Model (LLM) inference. In this blog post, we are excited to announce the open-sourcing of <strong><a href="https://github.com/sgl-project/SpecForge">SpecForge</a></strong>, our new training framework for Eagle3-based speculative decoding. SpecForge is designed for ease of use and is tightly integrated with the <strong><a href="https://github.com/sgl-project/sglang">SGLang</a></strong> inference engine, enabling a seamless transition from training to deployment.</p>
<h2><a id="why-a-new-speculative-decoding-training-framework" class="anchor" href="#why-a-new-speculative-decoding-training-framework" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why a New Speculative Decoding Training Framework</h2>
<p>While speculative decoding has emerged as a breakthrough for accelerating LLM inference, the lack of robust open-source tools for training draft models‚Äîa key component of this process‚Äîhas significantly hindered its adoption. Many existing Eagle3-based projects suffer from poor maintenance, limited functionality, or lack of compatibility with frameworks like SGLang. These limitations have become significant barriers to adoption and practical deployment.</p>
<p>To bridge the gap between research and deployment, we built <strong>SpecForge</strong>‚Äîa purpose-built ecosystem for training draft models that integrate natively with SGLang. As soon as training completes, models are ready for inference out of the box‚Äîno further adaptation needed. Meanwhile, training effective draft models for today‚Äôs frontier LLMs‚Äîsuch as Llama 4, DeepSeek, and other Mixture-of-Experts (MoE) models‚Äîrequires infrastructure that can handle their complexity and scale. SpecForge is purpose-built from the ground up to meet these demands, bridging the gap between cutting-edge research and real-world deployment.</p>
<p>Key Capabilities of SpecForge:</p>
<ul>
<li><strong>Native Support for Advanced Architectures</strong>: SpecForge supports cutting-edge models, including complex MoE layers and transformer variants.</li>
<li><strong>Scalable Distributed Training</strong>: Integrated with modern large-scale training strategies like Fully Sharded Data Parallel (FSDP) and Tensor Parallelism (TP), SpecForge allows efficient scaling across GPU clusters.</li>
<li><strong>Memory-Efficient Training</strong>: Optimized memory management techniques make it feasible to train draft models even for very large base models.</li>
</ul>
<h2><a id="key-features-of-specforge" class="anchor" href="#key-features-of-specforge" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Key Features of SpecForge</h2>
<h3><a id="eagle3-integration" class="anchor" href="#eagle3-integration" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Eagle3 Integration</h3>
<p>Eagle is a state-of-the-art method for speculative decoding designed to accelerate large language model inference. It achieves this by training a specialized, lightweight draft model to accurately predict the token distributions of a larger target model, leading to high acceptance rates and significant performance improvements.</p>
<p><img src="/images/blog/spec_forge/eagleintro.PNG" alt="intro.svg"></p>
<h4><a id="training-time-test-support" class="anchor" href="#training-time-test-support" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Training-time Test Support</h4>
<p>This high performance is largely driven by Eagle's novel Training-Time Test (TTT) architecture, which makes the draft model robust by simulating multi-step generation. Despite its power, TTT is notoriously difficult to implement due to its use of specialized attention masks and recursive data loops. SpecForge simplifies this complexity by providing built-in TTT support, referencing the official Eagle3 implementation to ensure correctness and optimal performance.</p>
<h3><a id="two-training-modes-online-and-offline" class="anchor" href="#two-training-modes-online-and-offline" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Two Training Modes: Online and Offline</h3>
<p>SpecForge simplifies hidden state collection by offering two versatile modes for training: <strong>Online</strong> and <strong>Offline</strong>. This two-mode design ensures flexibility across workflows, regardless of your model sizes or hardware limitations.</p>
<p><img src="/images/blog/spec_forge/offline_online.jpg" alt="offline_vs_online.svg"></p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Target Model Usage</th>
<th>Disk Space Requirement</th>
<th>GPU Requirement</th>
<th>One-liner Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td>Online</td>
<td>Used during training</td>
<td>Low</td>
<td>More GPUs if your target model is large</td>
<td>Generates hidden states on the fly</td>
</tr>
<tr>
<td>Offline</td>
<td>Used only for data preparation</td>
<td>High (e.g., UltraChat + ShareGPT need ~12TB)</td>
<td>As low as 1 GPU (only the draft model needs to be loaded)</td>
<td>Precomputes hidden states once and reuses them efficiently</td>
</tr>
</tbody>
</table>
<p>SpecForge allows you to tailor the training process to your specific needs. Choose Online Mode for agility and minimal disk usage‚Äîideal for rapid iteration. Choose Offline Mode when reproducibility and data reuse are key priorities, provided sufficient storage is available.</p>
<h3><a id="prioritizing-extensibility-and-scalability" class="anchor" href="#prioritizing-extensibility-and-scalability" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Prioritizing Extensibility and Scalability</h3>
<p>Our framework is designed with a strong emphasis on extensibility and scalability to meet engineering production requirements. We enable straightforward implementation and registration of new draft &amp; target models through a modular interface.</p>
<p>To support large-scale models, SpecForge leverages PyTorch‚Äôs FSDP and integrates tensor parallelism, ensuring efficient training across multi-GPU clusters.</p>
<h2><a id="experiments" class="anchor" href="#experiments" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Experiments</h2>
<p>Using SpecForge, we trained the Llama 4 Scout and Maverick models on a 320K-sample dataset from ShareGPT and UltraChat. The models' strong performance on benchmarks like MT-Bench demonstrates their effectiveness and readiness for Eagle3 inference. Our Llama 4 Maverick draft model achieves a 2.18√ó speedup on MT-Bench, while the Scout variant delivers a 2.0√ó acceleration‚Äîdemonstrating SpecForge‚Äôs performance gains across model variants. Detailed results are summarized below.</p>
<p>We evaluated various draft token lengths for Scout and Maverick.</p>
<p>In all the tests shown in the figure below, the x-axis represents steps, corresponding to <code>speculative-num-steps</code> in SGLang. Meanwhile, we fixed SGLang's <code>speculative-eagle-topk</code> to 8 and <code>speculative-num-draft-tokens</code> to 10 to ensure that <code>tree attention</code> can be enabled. To find the optimal speculative decoding parameters, we can use the <strong><a href="https://github.com/sgl-project/sglang/blob/main/scripts/playground/bench_speculative.py">bench_speculative</a></strong> script in the SGLang repository. It runs throughput benchmarks across different configurations and helps us tune for the best performance on the hardware.</p>
<p><img src="/images/blog/spec_forge/Llama4_Scout_performance_final.svg" alt="scout.svg"></p>
<p><img src="/images/blog/spec_forge/Llama4_Maverick_performance_final.svg" alt="maverick.svg"></p>
<h2><a id="code-and-model-availability" class="anchor" href="#code-and-model-availability" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Code and Model Availability</h2>
<p>Explore our source code on GitHub and try the pre-trained models on Hugging Face.</p>
<p><strong><a href="https://github.com/sgl-project/SpecForge">üíª GitHub Repository</a></strong>: The complete source code for our training framework, including implementation details for TTT and data processing.</p>
<p>ü§ó Hugging Face Models: Download the Llama 4 <a href="https://huggingface.co/lmsys/sglang-EAGLE3-Llama-4-Scout-17B-16E-Instruct-v1">Scout</a> &amp; <a href="https://huggingface.co/lmsys/sglang-EAGLE3-Llama-4-Maverick-17B-128E-Instruct-v1">Maverick</a> Eagle3 draft heads (excluding the full model) for your projects.</p>
<h2><a id="roadmap" class="anchor" href="#roadmap" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Roadmap</h2>
<p>In the near future, we plan to extend SpecForge with the following support.</p>
<ul>
<li>Support more model architectures, including the Kimi K2 and Qwen-3 MoE. We‚Äôre actively collaborating with the LinkedIn Infrastructure team, who are training additional Qwen-3 MoE draft models that will be supported by SpecForge.</li>
<li>Integrate Vision-Language Models (VLM) into SpecForge.</li>
<li>Support more efficient training with better parallelism strategies and kernel optimization.</li>
</ul>
<h2><a id="acknowledgement" class="anchor" href="#acknowledgement" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Acknowledgement</h2>
<p>We would like to express our heartfelt gratitude to the following teams and collaborators:</p>
<p><strong>SGLang Team and Community</strong> ‚Äî Shenggui Li, Yikai Zhu, Fan Yin, Chao Wang, Shuai Shi, Yi Zhang, Yingyi Huang, Haoshuai Zheng, Yubo Wang, Yineng Zhang and many others.</p>
<p><strong>SafeAILab Team</strong> ‚Äî Yuhui Li, Hongyang Zhang and members ‚Äî for their pioneering work on the Eagle3 algorithm.</p>
<p>We are especially grateful to Meituan for their early support and contributions to this project. We also extend our sincere thanks to <a href="https://www.voltagepark.com/">Voltage Park</a>, our official infrastructure partner, whose formal collaboration with the SGLang team provided the compute foundation behind SpecForge. Their support enabled us to train and evaluate large-scale speculative decoding models efficiently and reliably, and we deeply appreciate their commitment to democratizing cutting-edge AI infrastructure.</p>
<p>‚Äú<strong>Our mission at Voltage Park is to be a catalyst for innovation by democratizing access to high-performance AI infrastructure. A thriving AI research ecosystem is one where the tools to innovate are shaped by many voices and not concentrated in the hands of a few,</strong>&quot; said Saurabh Giri, Chief Product and Technology Officer at Voltage Park. &quot;<strong>This is why we are so proud to support the SGLang team with the critical infrastructure to develop high-quality, open-source projects like SpecForge -- we believe that foundational open-source models and frameworks should be for the public good and are essential for progress. We look forward to amazing applications from the community with these new capabilities.</strong>‚Äù</p>
<p>We're excited to see what the community will create with SpecForge. Whether you're optimizing existing models or training new ones, your feedback, contributions, and collaborations are all welcome‚Äîlet‚Äôs accelerate open-source LLM innovation together!</p>
</div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"SpecForge: Accelerating Speculative Decoding Training for SGLang","author":"The SGLang Team","date":"July 25, 2025","previewImg":"/images/blog/spec_forge/logo.jpg"},"content":"\nSpeculative decoding is a powerful technique for accelerating Large Language Model (LLM) inference. In this blog post, we are excited to announce the open-sourcing of **[SpecForge](https://github.com/sgl-project/SpecForge)**, our new training framework for Eagle3-based speculative decoding. SpecForge is designed for ease of use and is tightly integrated with the **[SGLang](https://github.com/sgl-project/sglang)** inference engine, enabling a seamless transition from training to deployment.\n\n## Why a New Speculative Decoding Training Framework\n\nWhile speculative decoding has emerged as a breakthrough for accelerating LLM inference, the lack of robust open-source tools for training draft models‚Äîa key component of this process‚Äîhas significantly hindered its adoption. Many existing Eagle3-based projects suffer from poor maintenance, limited functionality, or lack of compatibility with frameworks like SGLang. These limitations have become significant barriers to adoption and practical deployment.\n\nTo bridge the gap between research and deployment, we built **SpecForge**‚Äîa purpose-built ecosystem for training draft models that integrate natively with SGLang. As soon as training completes, models are ready for inference out of the box‚Äîno further adaptation needed. Meanwhile, training effective draft models for today‚Äôs frontier LLMs‚Äîsuch as Llama 4, DeepSeek, and other Mixture-of-Experts (MoE) models‚Äîrequires infrastructure that can handle their complexity and scale. SpecForge is purpose-built from the ground up to meet these demands, bridging the gap between cutting-edge research and real-world deployment.\n\nKey Capabilities of SpecForge:\n\n-   **Native Support for Advanced Architectures**: SpecForge supports cutting-edge models, including complex MoE layers and transformer variants.\n-   **Scalable Distributed Training**: Integrated with modern large-scale training strategies like Fully Sharded Data Parallel (FSDP) and Tensor Parallelism (TP), SpecForge allows efficient scaling across GPU clusters.\n-   **Memory-Efficient Training**: Optimized memory management techniques make it feasible to train draft models even for very large base models.\n\n## Key Features of SpecForge\n\n### Eagle3 Integration\n\nEagle is a state-of-the-art method for speculative decoding designed to accelerate large language model inference. It achieves this by training a specialized, lightweight draft model to accurately predict the token distributions of a larger target model, leading to high acceptance rates and significant performance improvements.\n\n![intro.svg](/images/blog/spec_forge/eagleintro.PNG)\n\n#### Training-time Test Support\n\nThis high performance is largely driven by Eagle's novel Training-Time Test (TTT) architecture, which makes the draft model robust by simulating multi-step generation. Despite its power, TTT is notoriously difficult to implement due to its use of specialized attention masks and recursive data loops. SpecForge simplifies this complexity by providing built-in TTT support, referencing the official Eagle3 implementation to ensure correctness and optimal performance.\n\n### Two Training Modes: Online and Offline\n\nSpecForge simplifies hidden state collection by offering two versatile modes for training: **Online** and **Offline**. This two-mode design ensures flexibility across workflows, regardless of your model sizes or hardware limitations.\n\n![offline_vs_online.svg](/images/blog/spec_forge/offline_online.jpg)\n\n  \n| Method  | Target Model Usage          | Disk Space Requirement                      | GPU Requirement                                            | One-liner Rationale                                      |\n|---------|-----------------------------|---------------------------------------------|------------------------------------------------------------|----------------------------------------------------------|\n| Online  | Used during training         | Low                                          | More GPUs if your target model is large                    | Generates hidden states on the fly                       |\n| Offline | Used only for data preparation | High (e.g., UltraChat + ShareGPT need ~12TB) | As low as 1 GPU (only the draft model needs to be loaded) | Precomputes hidden states once and reuses them efficiently |\n\nSpecForge allows you to tailor the training process to your specific needs. Choose Online Mode for agility and minimal disk usage‚Äîideal for rapid iteration. Choose Offline Mode when reproducibility and data reuse are key priorities, provided sufficient storage is available.\n\n### Prioritizing Extensibility and Scalability\n\nOur framework is designed with a strong emphasis on extensibility and scalability to meet engineering production requirements. We enable straightforward implementation and registration of new draft \u0026 target models through a modular interface.\n\nTo support large-scale models, SpecForge leverages PyTorch‚Äôs FSDP and integrates tensor parallelism, ensuring efficient training across multi-GPU clusters.\n\n## Experiments\n\nUsing SpecForge, we trained the Llama 4 Scout and Maverick models on a 320K-sample dataset from ShareGPT and UltraChat. The models' strong performance on benchmarks like MT-Bench demonstrates their effectiveness and readiness for Eagle3 inference. Our Llama 4 Maverick draft model achieves a 2.18√ó speedup on MT-Bench, while the Scout variant delivers a 2.0√ó acceleration‚Äîdemonstrating SpecForge‚Äôs performance gains across model variants. Detailed results are summarized below.\n\nWe evaluated various draft token lengths for Scout and Maverick.\n\nIn all the tests shown in the figure below, the x-axis represents steps, corresponding to `speculative-num-steps` in SGLang. Meanwhile, we fixed SGLang's `speculative-eagle-topk` to 8 and `speculative-num-draft-tokens` to 10 to ensure that `tree attention` can be enabled. To find the optimal speculative decoding parameters, we can use the **[bench_speculative](https://github.com/sgl-project/sglang/blob/main/scripts/playground/bench_speculative.py)** script in the SGLang repository. It runs throughput benchmarks across different configurations and helps us tune for the best performance on the hardware.\n\n![scout.svg](/images/blog/spec_forge/Llama4_Scout_performance_final.svg)\n\n![maverick.svg](/images/blog/spec_forge/Llama4_Maverick_performance_final.svg)\n\n## Code and Model Availability\n\nExplore our source code on GitHub and try the pre-trained models on Hugging Face.\n\n**[üíª GitHub Repository](https://github.com/sgl-project/SpecForge)**: The complete source code for our training framework, including implementation details for TTT and data processing.\n\nü§ó Hugging Face Models: Download the Llama 4 [Scout](https://huggingface.co/lmsys/sglang-EAGLE3-Llama-4-Scout-17B-16E-Instruct-v1) \u0026 [Maverick](https://huggingface.co/lmsys/sglang-EAGLE3-Llama-4-Maverick-17B-128E-Instruct-v1) Eagle3 draft heads (excluding the full model) for your projects.\n\n## Roadmap\n\nIn the near future, we plan to extend SpecForge with the following support.\n\n-   Support more model architectures, including the Kimi K2 and Qwen-3 MoE. We‚Äôre actively collaborating with the LinkedIn Infrastructure team, who are training additional Qwen-3 MoE draft models that will be supported by SpecForge.\n-   Integrate Vision-Language Models (VLM) into SpecForge.\n-   Support more efficient training with better parallelism strategies and kernel optimization.\n\n## Acknowledgement\n\nWe would like to express our heartfelt gratitude to the following teams and collaborators:\n\n**SGLang Team and Community** ‚Äî Shenggui Li, Yikai Zhu, Fan Yin, Chao Wang, Shuai Shi, Yi Zhang, Yingyi Huang, Haoshuai Zheng, Yubo Wang, Yineng Zhang and many others.\n\n**SafeAILab Team** ‚Äî Yuhui Li, Hongyang Zhang and members ‚Äî for their pioneering work on the Eagle3 algorithm.\n\nWe are especially grateful to Meituan for their early support and contributions to this project. We also extend our sincere thanks to [Voltage Park](https://www.voltagepark.com/), our official infrastructure partner, whose formal collaboration with the SGLang team provided the compute foundation behind SpecForge. Their support enabled us to train and evaluate large-scale speculative decoding models efficiently and reliably, and we deeply appreciate their commitment to democratizing cutting-edge AI infrastructure.\n\n‚Äú**Our mission at Voltage Park is to be a catalyst for innovation by democratizing access to high-performance AI infrastructure. A thriving AI research ecosystem is one where the tools to innovate are shaped by many voices and not concentrated in the hands of a few,**\" said Saurabh Giri, Chief Product and Technology Officer at Voltage Park. \"**This is why we are so proud to support the SGLang team with the critical infrastructure to develop high-quality, open-source projects like SpecForge -- we believe that foundational open-source models and frameworks should be for the public good and are essential for progress. We look forward to amazing applications from the community with these new capabilities.**‚Äù\n\nWe're excited to see what the community will create with SpecForge. Whether you're optimizing existing models or training new ones, your feedback, contributions, and collaborations are all welcome‚Äîlet‚Äôs accelerate open-source LLM innovation together!\n","slug":"2025-07-25-spec-forge"},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"2025-07-25-spec-forge"},"buildId":"lPJfP7GoXQIPsGhAR1mjA","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>