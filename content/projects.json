[
  {
    "name": "Models",
    "entries": [
      {
        "name": "Vicuna",
        "architecture": "Base: Llama",
        "size": "Size: 7B, 13B, 33B",
        "desc": "An open-source chatbot impressing GPT-4 with 90%* ChatGPT quality.",
        "link": "/blog/2023-03-30-vicuna"
      },
      { 
        "name": "LongChat",
        "architecture": "Base: Llama",
        "size": "Size: 7B, 13B",
        "desc": "A series of open-source chatbots with long context length (16K - 32K).",
        "link": "/blog/2023-06-29-longchat"
      },
      {
        "name": "FastChat-T5",
        "architecture": "Base: Flan-T5",
        "size": "Size: 3B",
        "desc": "A commercial-friendly, compact, yet powerful chat assistant.",
        "link": "https://huggingface.co/lmsys/fastchat-t5-3b-v1.0"
      }
    ]
  },
  {
    "name": "Datasets",
    "entries": [
      {
        "name": "LMSYS-Chat-1M",
        "architecture": "",
        "size": "",
        "desc": "This dataset contains one million real-world conversations with 25 state-of-the-art LLMs.",
        "link": "https://huggingface.co/datasets/lmsys/lmsys-chat-1m"
      },
      {
        "name": "Chatbot Arena Conversations",
        "architecture": "",
        "size": "",
        "desc": "This dataset contains 33K cleaned conversations with pairwise human preferences collected on Chatbot Arena.",
        "link": "https://huggingface.co/datasets/lmsys/chatbot_arena_conversations"
      },
      {
        "name": "ToxicChat",
        "architecture": "",
        "size": "",
        "desc": "This dataset contains 10K high-quality data for content moderation in real-world user-AI interactions based on user queries from the Vicuna online demo.",
        "link": "https://huggingface.co/datasets/lmsys/toxic-chat"
      }
    ]
  },
  {
    "name": "Evaluation",
    "entries": [
      {
        "name": "Chatbot Arena",
        "architecture": "",
        "size": "",
        "desc": "A benchmark platform for large language models (LLMs) that features anonymous, randomized battles in a crowdsourced manner. It comes with a leaderboard based on Elo ratings.",
        "link": "https://chat.lmsys.org/"
      },
      {
        "name": "MT-Bench",
        "architecture": "",
        "size": "",
        "desc": "A set of challenging, multi-turn, and open-ended questions for evaluating chat assistants. It uses LLM-as-a-judge to evaluate model responses.",
        "link": "https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge"
      }
    ]
  },
  {
    "name": "Systems",
    "entries": [
      {
        "name": "FastChat",
        "architecture": "",
        "size": "",
        "desc": "An open and scalable platform for training, finetuning, serving, and evaluating LLM-based chatbots.",
        "link": "https://github.com/lm-sys/FastChat"
      },
      {
        "name": "S-LoRA",
        "architecture": "",
        "size": "",
        "desc": "A scalable serving system for multiple concurrent LoRA adapters.",
        "link": "https://github.com/S-LoRA/S-LoRA"
      },
      {
        "name": "Lookahead Decoding",
        "architecture": "",
        "size": "",
        "desc": "An exact, fast, parallel decoding algorithm without the need for draft models or data stores.",
        "link": "https://github.com/hao-ai-lab/LookaheadDecoding"
      }
    ]
  }
]
